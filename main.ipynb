{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6c89cfe1-6927-44c6-8e2d-373f3f5bcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('Cancer_dataset1.csv')\n",
    "\n",
    "for i in df.outcome:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8678835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN RADIUS\n",
      "Mean Radius Count = 194\n",
      "Mean Radius Mean = 17.412061855670103\n",
      "Mean Radius Standard Deviation = 3.1571814471858555\n",
      "Mean Radius Minimum = 10.95\n",
      "Mean Radius 25% percentile = 15.0525\n",
      "Mean Radius 50% percentile = 17.28\n",
      "Mean Radius 75% percentile = 19.58\n",
      "Mean Radius Maximum = 27.22\n",
      "\n",
      "\n",
      "MEAN TEXTURE\n",
      "Mean Texture Count = 194\n",
      "Mean Texture Mean = 22.3190206185567\n",
      "Mean Texture Standard Deviation = 4.283068191040899\n",
      "Mean Texture Minimum = 10.38\n",
      "Mean Texture 25% percentile = 19.517500000000002\n",
      "Mean Texture 50% percentile = 21.795\n",
      "Mean Texture 75% percentile = 24.655\n",
      "Mean Texture Maximum = 39.28\n",
      "\n",
      "\n",
      "MEAN PERIMETER\n",
      "Mean Perimeter Count = 198\n",
      "Mean Perimeter Mean = 114.85656565656565\n",
      "Mean Perimeter Standard Deviation = 21.383401559552883\n",
      "Mean Perimeter Minimum = 71.9\n",
      "Mean Perimeter 25% percentile = 98.16\n",
      "Mean Perimeter 50% percentile = 113.7\n",
      "Mean Perimeter 75% percentile = 129.64999999999998\n",
      "Mean Perimeter Maximum = 182.1\n",
      "\n",
      "\n",
      "MEAN AREA\n",
      "Mean Area Count = 198\n",
      "Mean Area Mean = 970.0409090909089\n",
      "Mean Area Standard Deviation = 352.14921516208284\n",
      "Mean Area Minimum = 361.6\n",
      "Mean Area 25% percentile = 702.525\n",
      "Mean Area 50% percentile = 929.0999999999999\n",
      "Mean Area 75% percentile = 1193.5\n",
      "Mean Area Maximum = 2250.0\n",
      "\n",
      "\n",
      "MEAN SMOOTHNESS\n",
      "Mean Smoothness Count = 198\n",
      "Mean Smoothness Mean = 0.10268141414141414\n",
      "Mean Smoothness Standard Deviation = 0.012522431569239916\n",
      "Mean Smoothness Minimum = 0.07497\n",
      "Mean Smoothness 25% percentile = 0.0939\n",
      "Mean Smoothness 50% percentile = 0.10189999999999999\n",
      "Mean Smoothness 75% percentile = 0.110975\n",
      "Mean Smoothness Maximum = 0.1447\n",
      "\n",
      "\n",
      "MEAN COMPACTNESS\n",
      "Mean Compactness Count = 198\n",
      "Mean Compactness Mean = 0.14264777777777776\n",
      "Mean Compactness Standard Deviation = 0.049897601888512416\n",
      "Mean Compactness Minimum = 0.04605\n",
      "Mean Compactness 25% percentile = 0.11019999999999999\n",
      "Mean Compactness 50% percentile = 0.13175\n",
      "Mean Compactness 75% percentile = 0.17220000000000002\n",
      "Mean Compactness Maximum = 0.3114\n",
      "\n",
      "\n",
      "MEAN CONCAVITY\n",
      "Mean Concavity Count = 198\n",
      "Mean Concavity Mean = 0.15624277777777776\n",
      "Mean Concavity Standard Deviation = 0.07057226120534643\n",
      "Mean Concavity Minimum = 0.02398\n",
      "Mean Concavity 25% percentile = 0.10685\n",
      "Mean Concavity 50% percentile = 0.15134999999999998\n",
      "Mean Concavity 75% percentile = 0.2005\n",
      "Mean Concavity Maximum = 0.4268\n",
      "\n",
      "\n",
      "MEAN CONCAVE POINTS\n",
      "Mean Concave Points Count = 198\n",
      "Mean Concave Points Mean = 0.08677560606060604\n",
      "Mean Concave Points Standard Deviation = 0.03387663129061639\n",
      "Mean Concave Points Minimum = 0.02031\n",
      "Mean Concave Points 25% percentile = 0.06367\n",
      "Mean Concave Points 50% percentile = 0.086075\n",
      "Mean Concave Points 75% percentile = 0.103925\n",
      "Mean Concave Points Maximum = 0.2012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1A)\n",
    "\n",
    "#Summary statistics for mean_radius\n",
    "print(\"MEAN RADIUS\")\n",
    "print(f\"Mean Radius Count = {df['mean_radius'].count()}\")\n",
    "print(f\"Mean Radius Mean = {df['mean_radius'].mean()}\")\n",
    "print(f\"Mean Radius Standard Deviation = {df['mean_radius'].std()}\")\n",
    "print(f\"Mean Radius Minimum = {df['mean_radius'].min()}\")\n",
    "print(f\"Mean Radius 25% percentile = {df['mean_radius'].quantile(0.25)}\")\n",
    "print(f\"Mean Radius 50% percentile = {df['mean_radius'].quantile(0.50)}\")\n",
    "print(f\"Mean Radius 75% percentile = {df['mean_radius'].quantile(0.75)}\")\n",
    "print(f\"Mean Radius Maximum = {df['mean_radius'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN TEXTURE\")\n",
    "print(f\"Mean Texture Count = {df['mean_texture'].count()}\")\n",
    "print(f\"Mean Texture Mean = {df['mean_texture'].mean()}\")\n",
    "print(f\"Mean Texture Standard Deviation = {df['mean_texture'].std()}\")\n",
    "print(f\"Mean Texture Minimum = {df['mean_texture'].min()}\")\n",
    "print(f\"Mean Texture 25% percentile = {df['mean_texture'].quantile(0.25)}\")\n",
    "print(f\"Mean Texture 50% percentile = {df['mean_texture'].quantile(0.50)}\")\n",
    "print(f\"Mean Texture 75% percentile = {df['mean_texture'].quantile(0.75)}\")\n",
    "print(f\"Mean Texture Maximum = {df['mean_texture'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN PERIMETER\")\n",
    "print(f\"Mean Perimeter Count = {df['mean_perimeter'].count()}\")\n",
    "print(f\"Mean Perimeter Mean = {df['mean_perimeter'].mean()}\")\n",
    "print(f\"Mean Perimeter Standard Deviation = {df['mean_perimeter'].std()}\")\n",
    "print(f\"Mean Perimeter Minimum = {df['mean_perimeter'].min()}\")\n",
    "print(f\"Mean Perimeter 25% percentile = {df['mean_perimeter'].quantile(0.25)}\")\n",
    "print(f\"Mean Perimeter 50% percentile = {df['mean_perimeter'].quantile(0.50)}\")\n",
    "print(f\"Mean Perimeter 75% percentile = {df['mean_perimeter'].quantile(0.75)}\")\n",
    "print(f\"Mean Perimeter Maximum = {df['mean_perimeter'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN AREA\")\n",
    "print(f\"Mean Area Count = {df['mean_area'].count()}\")\n",
    "print(f\"Mean Area Mean = {df['mean_area'].mean()}\")\n",
    "print(f\"Mean Area Standard Deviation = {df['mean_area'].std()}\")\n",
    "print(f\"Mean Area Minimum = {df['mean_area'].min()}\")\n",
    "print(f\"Mean Area 25% percentile = {df['mean_area'].quantile(0.25)}\")\n",
    "print(f\"Mean Area 50% percentile = {df['mean_area'].quantile(0.50)}\")\n",
    "print(f\"Mean Area 75% percentile = {df['mean_area'].quantile(0.75)}\")\n",
    "print(f\"Mean Area Maximum = {df['mean_area'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN SMOOTHNESS\")\n",
    "print(f\"Mean Smoothness Count = {df['mean_smoothness'].count()}\")\n",
    "print(f\"Mean Smoothness Mean = {df['mean_smoothness'].mean()}\")\n",
    "print(f\"Mean Smoothness Standard Deviation = {df['mean_smoothness'].std()}\")\n",
    "print(f\"Mean Smoothness Minimum = {df['mean_smoothness'].min()}\")\n",
    "print(f\"Mean Smoothness 25% percentile = {df['mean_smoothness'].quantile(0.25)}\")\n",
    "print(f\"Mean Smoothness 50% percentile = {df['mean_smoothness'].quantile(0.50)}\")\n",
    "print(f\"Mean Smoothness 75% percentile = {df['mean_smoothness'].quantile(0.75)}\")\n",
    "print(f\"Mean Smoothness Maximum = {df['mean_smoothness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN COMPACTNESS\")\n",
    "print(f\"Mean Compactness Count = {df['mean_compactness'].count()}\")\n",
    "print(f\"Mean Compactness Mean = {df['mean_compactness'].mean()}\")\n",
    "print(f\"Mean Compactness Standard Deviation = {df['mean_compactness'].std()}\")\n",
    "print(f\"Mean Compactness Minimum = {df['mean_compactness'].min()}\")\n",
    "print(f\"Mean Compactness 25% percentile = {df['mean_compactness'].quantile(0.25)}\")\n",
    "print(f\"Mean Compactness 50% percentile = {df['mean_compactness'].quantile(0.50)}\")\n",
    "print(f\"Mean Compactness 75% percentile = {df['mean_compactness'].quantile(0.75)}\")\n",
    "print(f\"Mean Compactness Maximum = {df['mean_compactness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVITY\")\n",
    "print(f\"Mean Concavity Count = {df['mean_concavity'].count()}\")\n",
    "print(f\"Mean Concavity Mean = {df['mean_concavity'].mean()}\")\n",
    "print(f\"Mean Concavity Standard Deviation = {df['mean_concavity'].std()}\")\n",
    "print(f\"Mean Concavity Minimum = {df['mean_concavity'].min()}\")\n",
    "print(f\"Mean Concavity 25% percentile = {df['mean_concavity'].quantile(0.25)}\")\n",
    "print(f\"Mean Concavity 50% percentile = {df['mean_concavity'].quantile(0.50)}\")\n",
    "print(f\"Mean Concavity 75% percentile = {df['mean_concavity'].quantile(0.75)}\")\n",
    "print(f\"Mean Concavity Maximum = {df['mean_concavity'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVE POINTS\")\n",
    "print(f\"Mean Concave Points Count = {df['mean_concave_points'].count()}\")\n",
    "print(f\"Mean Concave Points Mean = {df['mean_concave_points'].mean()}\")\n",
    "print(f\"Mean Concave Points Standard Deviation = {df['mean_concave_points'].std()}\")\n",
    "print(f\"Mean Concave Points Minimum = {df['mean_concave_points'].min()}\")\n",
    "print(f\"Mean Concave Points 25% percentile = {df['mean_concave_points'].quantile(0.25)}\")\n",
    "print(f\"Mean Concave Points 50% percentile = {df['mean_concave_points'].quantile(0.50)}\")\n",
    "print(f\"Mean Concave Points 75% percentile = {df['mean_concave_points'].quantile(0.75)}\")\n",
    "print(f\"Mean Concave Points Maximum = {df['mean_concave_points'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3879b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTCOME\n",
      "Outcome Count = 198\n",
      "Outcome unique values are = ['N' 'R']\n",
      "Count of each unique values are = N    151\n",
      "R     47\n",
      "Name: outcome, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 1B)\n",
    "\n",
    "print(\"OUTCOME\")\n",
    "print(f\"Outcome Count = {df['outcome'].count()}\")\n",
    "print(f\"Outcome unique values are = {df['outcome'].unique()}\")\n",
    "print(f\"Count of each unique values are = {df['outcome'].value_counts()}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9dfb77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1C)\n",
    "df['outcome'].replace('N', 0, inplace=True) \n",
    "df['outcome'].replace('R', 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2e1e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean_perimeter  se_perimeter\n",
      "mean_perimeter        1.000000      0.609964\n",
      "se_perimeter          0.609964      1.000000\n"
     ]
    }
   ],
   "source": [
    "# Question 1E)\n",
    "print(df[['mean_perimeter','se_perimeter']].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3df45305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Class for cleaning up data and data manipulation in general\n",
    "class DataManipulation:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def cleanUpData(self):\n",
    "        self.df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    def divideData(self):\n",
    "        \n",
    "        df_positive = self.df[self.df['outcome'] == 1]\n",
    "        df_negative = self.df[self.df['outcome'] != 1]\n",
    "        \n",
    "        print(len(df_positive))\n",
    "        print(len(df_negative))\n",
    "\n",
    "        df_positive_train = df_positive.sample(n=35)\n",
    "        df_negative_train = df_negative.sample(n=42)\n",
    "\n",
    "        df_positive_test =  df_positive[~df_positive.apply(tuple, axis=1).isin(df_positive_train.apply(tuple, axis=1))]\n",
    "        df_negative_test =  df_negative[~df_negative.apply(tuple, axis=1).isin(df_negative_train.apply(tuple, axis=1))]\n",
    "        \n",
    "        train = pd.concat([df_positive_train, df_negative_train], ignore_index=True)\n",
    "        test = pd.concat([df_positive_test, df_negative_test], ignore_index=True)\n",
    "        \n",
    "\n",
    "        return train, test\n",
    "\n",
    "    # def divideData(self):\n",
    "         \n",
    "\n",
    "    #     return train, test\n",
    "    \n",
    "    def reqColsFromData(self, cols, data : pd.DataFrame):\n",
    "        finalData = []\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            predictorsArr = []\n",
    "\n",
    "            for col in cols:\n",
    "                predictorsArr.append(row[col])\n",
    "        \n",
    "            finalData.append((predictorsArr, row['outcome']))\n",
    "            \n",
    "        \n",
    "        return finalData\n",
    "    \n",
    "    def performMinMaxScaling(self, data):\n",
    "\n",
    "        for x in data:\n",
    "            for index, _ in enumerate(x[0]):\n",
    "                MAX, MIN = self.getMaxAndMinOfCol(index, data)\n",
    "                x[0][index] = (Decimal(x[0][index]) - MIN) / (MAX - MIN)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def getMaxAndMinOfCol(self, col, data):    \n",
    "        dataOfCol = []\n",
    "\n",
    "        for x in data:\n",
    "            dataOfCol.append(Decimal(x[0][col]))\n",
    "\n",
    "        return max(dataOfCol), min(dataOfCol)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic regression model Class with all the components required for Logistic regression\n",
    "class LogisticRegression:\n",
    "    \n",
    "    trainingData = None\n",
    "    testData = None\n",
    "    maxNoOfIterations = 1000\n",
    "\n",
    "    def __init__(self, trainingData, testData, thetas, lr, isRegularization):\n",
    "        self.trainingData = trainingData\n",
    "        self.testData = testData\n",
    "        self.thetas = thetas\n",
    "        self.lr = lr\n",
    "        self.isRegularization = isRegularization\n",
    "        \n",
    "        \n",
    "    def getFeatures2D(self, data):\n",
    "        if data != None:\n",
    "            features = [x[0] for x in data]\n",
    "            return features\n",
    "\n",
    "    def getOutputs(self, data):\n",
    "        if data != None:\n",
    "            output = [Decimal(x[1]) for x in data]\n",
    "            return output\n",
    "\n",
    "    def performLogisticRegression(self):\n",
    "        self.iterate()\n",
    "\n",
    "    def computePredictedOutput(self, thetas, data):\n",
    "        predictedOutputs = []\n",
    "\n",
    "        for x in self.getFeatures2D(data):\n",
    "            y = Decimal(thetas[0])\n",
    "\n",
    "            for idx, i in enumerate(x):\n",
    "                y += (Decimal(thetas[idx + 1]) * Decimal(i))\n",
    "\n",
    "            \n",
    "            Y = Decimal(1 / (1 + np.exp(-y) ))\n",
    "            \n",
    "            predictedOutputs.append(Y)\n",
    "\n",
    "        return predictedOutputs\n",
    "    \n",
    "\n",
    "    def calculateGradientDescent(self, B, index,  predictedOutputs, isIntercept):\n",
    "        features = self.getFeatures2D(self.trainingData)\n",
    "        outputs = self.getOutputs(self.trainingData)\n",
    "\n",
    "        dataLen = Decimal(len(features))\n",
    "        \n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(features):\n",
    "\n",
    "            if isIntercept:\n",
    "                result = (predictedOutputs[idx] - outputs[idx])\n",
    "            else:\n",
    "                result = (predictedOutputs[idx] - outputs[idx]) * Decimal(x[index]) \n",
    "\n",
    "\n",
    "            total += result\n",
    "\n",
    "        if self.isRegularization and (not isIntercept):\n",
    "            total += (100 * B) / dataLen # regularization coefficent = 100\n",
    "        \n",
    "        change = (Decimal(self.lr) * total) / dataLen\n",
    "\n",
    "        newB = Decimal(B) - change\n",
    "\n",
    "        \n",
    "        return newB\n",
    "    \n",
    "    def iterate(self):\n",
    "        \n",
    "\n",
    "        for i in range(self.maxNoOfIterations):\n",
    "\n",
    "            predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "\n",
    "            for idx, b in enumerate(self.thetas):\n",
    "                if idx == 0:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, True)\n",
    "                else:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, False)\n",
    "\n",
    "                self.thetas[idx] = newB\n",
    "\n",
    "            # predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "            # cost = self.calculateCost(predictedOutputs, self.trainingData)\n",
    "                \n",
    "            # if abs(cost - self.previousCost) < 0.1:\n",
    "            #     break\n",
    "            # else:\n",
    "            #     self.previousCost = cost\n",
    "        \n",
    "        self.printResults()\n",
    "\n",
    "    def calculateCost(self, predictedOutputs, data):\n",
    "        outputs = self.getOutputs(data)\n",
    "        dataLen = len(self.getFeatures2D(data))\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            result = (outputs[idx] * x.log10()) + ((1 - outputs[idx]) * (1 - x).log10())\n",
    "            total += result\n",
    "\n",
    "        return -(total/dataLen)\n",
    "\n",
    "    \n",
    "    def calculateF1Score(self, predictedOutputs, data, threshold):\n",
    "        outputs = self.getOutputs(data)\n",
    "       \n",
    "        roundedPredictedOutputs = []\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            print(x)\n",
    "            if x > threshold:  \n",
    "                roundedPredictedOutputs.append(1)\n",
    "            else:\n",
    "                roundedPredictedOutputs.append(0)\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "\n",
    "        for idx, x in enumerate(roundedPredictedOutputs):\n",
    "            if x == outputs[idx]:\n",
    "                TP += 1\n",
    "            elif outputs[idx] == 1 and x == 0:\n",
    "                FN += 1\n",
    "            elif outputs[idx] == 0 and x == 1:\n",
    "                FP += 1\n",
    "        \n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            \n",
    "\n",
    "        return f1\n",
    "\n",
    "    def printResults(self):\n",
    "        print(\"The values of the Thetas/ Weights are\")\n",
    "        print(self.thetas)\n",
    "\n",
    "        \n",
    "        # predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "        \n",
    "        # cost = self.calculateCost(predictedOutputs, self.trainingData)\n",
    "        # print(f\"Cost of the Training data is: {cost}\")\n",
    "\n",
    "        # F1Score = self.calculateF1Score(predictedOutputs, self.trainingData, 0.5)\n",
    "        # print(f\"F1 Score of the Training data is: {F1Score}\")\n",
    "\n",
    "        \n",
    "        predictedOutputs = self.computePredictedOutput(self.thetas, self.testData)\n",
    "\n",
    "        cost = self.calculateCost(predictedOutputs, self.testData)\n",
    "        print(f\"Cost of the Test data is: {cost}\")\n",
    "\n",
    "        F1Score = self.calculateF1Score(predictedOutputs, self.testData, 0.5)\n",
    "        print(f\"F1 Score of the Test data is: {F1Score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5ccbd89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# Getting data ready for logistic regression\n",
    "\n",
    "dm = DataManipulation(df)\n",
    "dm.cleanUpData()\n",
    "\n",
    "train, test = dm.divideData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "33e9abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-4.508912280751136847891779196'), Decimal('0.3291721141121106947903630725')]\n",
      "Cost of the Test data is: 0.01934377809694068996287184508\n",
      "0.05401056577391219663770850042\n",
      "0.07351696109857907452579392264\n",
      "0.9982628442875463168761569276\n",
      "F1 Score of the Test data is: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finalTrain = [([1], 0), ([2], 0), ([3], 0), ([30], 1), ([40], 1)]\n",
    "finalTest = [([5], 0), ([6], 0), ([33], 1)]\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2], 0.1, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr.performLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ff0d2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "105\n",
      "The values of the Thetas/ Weights are\n",
      "[Decimal('0.03979217019355549481943421821'), Decimal('0.0430621607683496524243856909')]\n"
     ]
    },
    {
     "ename": "InvalidOperation",
     "evalue": "[<class 'decimal.InvalidOperation'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperation\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(finalTrain, finalTest, [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m], \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66m# passing in Training data, Test data, max no of iteration, starting theta values,\u001b[39m\n\u001b[1;32m     12\u001b[0m                                                                   \u001b[38;5;66m# the learning date and regularization\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperformLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[232], line 96\u001b[0m, in \u001b[0;36mLogisticRegression.performLogisticRegression\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperformLogisticRegression\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[232], line 166\u001b[0m, in \u001b[0;36mLogisticRegression.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthetas[idx] \u001b[38;5;241m=\u001b[39m newB\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66m# predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\u001b[39m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66m# cost = self.calculateCost(predictedOutputs, self.trainingData)\u001b[39m\n\u001b[1;32m    160\u001b[0m         \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66m# else:\u001b[39m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66m#     self.previousCost = cost\u001b[39m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprintResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[232], line 229\u001b[0m, in \u001b[0;36mLogisticRegression.printResults\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66m# predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\u001b[39m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[38;5;66m# cost = self.calculateCost(predictedOutputs, self.trainingData)\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66m# F1Score = self.calculateF1Score(predictedOutputs, self.trainingData, 0.5)\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66m# print(f\"F1 Score of the Training data is: {F1Score}\")\u001b[39m\n\u001b[1;32m    227\u001b[0m predictedOutputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputePredictedOutput(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthetas, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestData)\n\u001b[0;32m--> 229\u001b[0m cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculateCost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictedOutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtestData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mprint\u001b[39m(f\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCost of the Test data is: \u001b[39m\u001b[38;5;132;01m{cost}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m F1Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculateF1Score(predictedOutputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestData, \u001b[38;5;241m0.5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[232], line 175\u001b[0m, in \u001b[0;36mLogisticRegression.calculateCost\u001b[0;34m(self, predictedOutputs, data)\u001b[0m\n\u001b[1;32m    172\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictedOutputs):\n\u001b[0;32m--> 175\u001b[0m     result \u001b[38;5;241m=\u001b[39m (outputs[idx] \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39mlog10()) \u001b[38;5;241m+\u001b[39m (\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog10\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    176\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m(total\u001b[38;5;241m/\u001b[39mdataLen)\n",
      "\u001b[0;31mInvalidOperation\u001b[0m: [<class 'decimal.InvalidOperation'>]"
     ]
    }
   ],
   "source": [
    "# Question 2A and 2B\n",
    "finalTrain = dm.reqColsFromData(['mean_area'], train)\n",
    "finalTest = dm.reqColsFromData(['mean_area'], test)\n",
    "\n",
    "print(len(finalTrain))\n",
    "print(len(finalTest))\n",
    "\n",
    "# finalTrain = dm.performMinMaxScaling(tempTrain)\n",
    "# finalTest = dm.performMinMaxScaling(tempTest)\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2], 0.001, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr.performLogisticRegression()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87584c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('0.09591257759650599742204491731'), Decimal('0.1602463050429842230828695779'), Decimal('-0.01791959882411743357500530533'), Decimal('-0.1613964073308319519477937576'), Decimal('0.01928851726952014216531315813'), Decimal('0.1995831632268424839837899001'), Decimal('0.09922865567927424398245141097'), Decimal('0.2991304423678242224335927153'), Decimal('-0.0002573239851828329410715288240'), Decimal('0.09969098294085257829739129962'), Decimal('0.1985303088116458752585703612'), Decimal('0.2900017826874352185655595117'), Decimal('0.1175860328366005948300238450')]\n",
      "Cost of the Test data is: 4.599896980603158155480449078\n",
      "0.9994838180585208824593056443\n",
      "0.9632030934985323634387989595\n",
      "0.9999999850856003201779677440\n",
      "0.8487958118420528217405128230\n",
      "0.9999972894321127506751993809\n",
      "0.9999990926982281804434056541\n",
      "0.9999974568536548117599692619\n",
      "0.9999999873864849190726062346\n",
      "0.6998203156055520065934320453\n",
      "0.8065209945533378404111619582\n",
      "0.9987648506982630343650878982\n",
      "0.9963608992832510186326825123\n",
      "0.9999998275606326027204337023\n",
      "0.8839520554539002141887455992\n",
      "0.9999999515796137313771643269\n",
      "0.9972488433264919619799582250\n",
      "0.9999818641219033180814320475\n",
      "0.9999800234981886978619496198\n",
      "0.9999985785700723761849278869\n",
      "0.9959097347374730113787101404\n",
      "0.9486520373850080661053171078\n",
      "0.9999996424840741974814636742\n",
      "0.7555594726308114327799987830\n",
      "0.8601059357395191901197632991\n",
      "0.4669261916480276601103657928\n",
      "0.9404639733979458146600955885\n",
      "0.6195765409032532730077827144\n",
      "0.9932241359356789185146453310\n",
      "0.9864812168340673269678116328\n",
      "0.9999864726115916588006168787\n",
      "0.9999999999960090940783355383\n",
      "0.9980294537948857445426162982\n",
      "0.9685512706044593776545692521\n",
      "0.9949005581542752429307407158\n",
      "0.9528537278913876346217446894\n",
      "0.9946852532367147992480742505\n",
      "0.9997466392703797900649378355\n",
      "0.9999998991415255078908993385\n",
      "0.9999999999999999987255856460\n",
      "0.9999981941149849503582697798\n",
      "0.9999989721357981818618817622\n",
      "0.9999999996676908469308648903\n",
      "0.9999849121727677404661456984\n",
      "0.9999984584328813471631298658\n",
      "0.9936619906399552700182834814\n",
      "0.9978410653676510648301980359\n",
      "0.9335083140832377264161274696\n",
      "0.9666438783009630344103338781\n",
      "0.9458524978839935568946470419\n",
      "0.9978710981584494762330021256\n",
      "0.9999928561534704375955283157\n",
      "0.9999999995482071915151464339\n",
      "0.9999995879992434135116819869\n",
      "0.9755692108240945241162069355\n",
      "0.9999999997235504366996336981\n",
      "0.9934191795985135138273562308\n",
      "0.9999998918716136261011242581\n",
      "0.9999999999999622480613651394\n",
      "0.9999994219462049107785888295\n",
      "0.9994891325988040434408029341\n",
      "0.9817324181636778794223672464\n",
      "0.9999999999999980965622739900\n",
      "0.9999324915277822270660305818\n",
      "0.9999988866090906708922654625\n",
      "0.9889419180996962850179113832\n",
      "0.9940154529785165329166442768\n",
      "0.9999999998683584725290034588\n",
      "0.9999999097834846969348085663\n",
      "0.9999996094646759681625573533\n",
      "0.9999993748805587124061118043\n",
      "0.9989543600609727369258696293\n",
      "0.9999998887843506463811791158\n",
      "0.9999999959010799473537229299\n",
      "0.9999999671715338962843053283\n",
      "0.2822346589148273067600198276\n",
      "0.9906137489860489849397633511\n",
      "0.9999999803135460501063304469\n",
      "0.9999264844397593537918874975\n",
      "0.9987805985361839214806878132\n",
      "0.9999999835118575243398589351\n",
      "0.9999999909908392524701380941\n",
      "0.9948675349451504301540832107\n",
      "0.9927440080565805138659203931\n",
      "0.9999999230048733892323725365\n",
      "0.9848860870572318330825384227\n",
      "0.9898742434354340360537991920\n",
      "0.9999999999999527369206719332\n",
      "0.9999363613422168782216365345\n",
      "0.9389131495461126927225182059\n",
      "0.9985064654555960840694505773\n",
      "0.9999999999372652695277380114\n",
      "0.9999999988005651534731166318\n",
      "0.9952091274901682495324452691\n",
      "0.9699046605799291154135289423\n",
      "0.9999996756891692417069967585\n",
      "0.9124457815191934885069567425\n",
      "0.9999999999999999999336381560\n",
      "0.9309493320478236076540592807\n",
      "0.9999999993529301751519193895\n",
      "0.9999995199613111087184479686\n",
      "0.9312444118437063969925585791\n",
      "0.9999999999999996941760369450\n",
      "0.9920543814821316417513565869\n",
      "0.9999807555349322442025209649\n",
      "0.9999671875547132196174953209\n",
      "F1 Score of the Test data is: 0.14159292035398233\n"
     ]
    }
   ],
   "source": [
    "#Question 3A\n",
    "\n",
    "finalTrain = dm.reqColsFromData(['mean_radius',\n",
    "                                'mean_texture',\n",
    "                                'mean_perimeter',\n",
    "                                'mean_area',\n",
    "                                'mean_smoothness',\n",
    "                                'mean_compactness',\n",
    "                                'mean_concavity',\n",
    "                                'mean_concave_points',\n",
    "                                'mean_fractal_dimension',\n",
    "                                'se_perimeter',\n",
    "                                'se_texture',\n",
    "                                'se_area'], train)\n",
    "finalTest = dm.reqColsFromData(['mean_radius',\n",
    "                                'mean_texture',\n",
    "                                'mean_perimeter',\n",
    "                                'mean_area',\n",
    "                                'mean_smoothness',\n",
    "                                'mean_compactness',\n",
    "                                'mean_concavity',\n",
    "                                'mean_concave_points',\n",
    "                                'mean_fractal_dimension',\n",
    "                                'se_perimeter',\n",
    "                                'se_texture',\n",
    "                                'se_area'], test)\n",
    "\n",
    "\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2, 0.1, 0.1, 0.0, 0.2, 0.1, 0.3, 0.0, 0.1, 0.2, 0.3, 0.0], 0.0001, False) \n",
    "lr.performLogisticRegression() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b87798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
