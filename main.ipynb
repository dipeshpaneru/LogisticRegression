{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1223,
   "id": "6c89cfe1-6927-44c6-8e2d-373f3f5bcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('Cancer_dataset1.csv')\n",
    "\n",
    "for i in df.outcome:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "id": "8678835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN RADIUS\n",
      "Mean Radius Count = 194\n",
      "Mean Radius Mean = 17.412061855670103\n",
      "Mean Radius Standard Deviation = 3.1571814471858555\n",
      "Mean Radius Minimum = 10.95\n",
      "Mean Radius 25% percentile = 15.0525\n",
      "Mean Radius 50% percentile = 17.28\n",
      "Mean Radius 75% percentile = 19.58\n",
      "Mean Radius Maximum = 27.22\n",
      "\n",
      "\n",
      "MEAN TEXTURE\n",
      "Mean Texture Count = 194\n",
      "Mean Texture Mean = 22.3190206185567\n",
      "Mean Texture Standard Deviation = 4.283068191040899\n",
      "Mean Texture Minimum = 10.38\n",
      "Mean Texture 25% percentile = 19.517500000000002\n",
      "Mean Texture 50% percentile = 21.795\n",
      "Mean Texture 75% percentile = 24.655\n",
      "Mean Texture Maximum = 39.28\n",
      "\n",
      "\n",
      "MEAN PERIMETER\n",
      "Mean Perimeter Count = 198\n",
      "Mean Perimeter Mean = 114.85656565656565\n",
      "Mean Perimeter Standard Deviation = 21.383401559552883\n",
      "Mean Perimeter Minimum = 71.9\n",
      "Mean Perimeter 25% percentile = 98.16\n",
      "Mean Perimeter 50% percentile = 113.7\n",
      "Mean Perimeter 75% percentile = 129.64999999999998\n",
      "Mean Perimeter Maximum = 182.1\n",
      "\n",
      "\n",
      "MEAN AREA\n",
      "Mean Area Count = 198\n",
      "Mean Area Mean = 970.0409090909089\n",
      "Mean Area Standard Deviation = 352.14921516208284\n",
      "Mean Area Minimum = 361.6\n",
      "Mean Area 25% percentile = 702.525\n",
      "Mean Area 50% percentile = 929.0999999999999\n",
      "Mean Area 75% percentile = 1193.5\n",
      "Mean Area Maximum = 2250.0\n",
      "\n",
      "\n",
      "MEAN SMOOTHNESS\n",
      "Mean Smoothness Count = 198\n",
      "Mean Smoothness Mean = 0.10268141414141414\n",
      "Mean Smoothness Standard Deviation = 0.012522431569239916\n",
      "Mean Smoothness Minimum = 0.07497\n",
      "Mean Smoothness 25% percentile = 0.0939\n",
      "Mean Smoothness 50% percentile = 0.10189999999999999\n",
      "Mean Smoothness 75% percentile = 0.110975\n",
      "Mean Smoothness Maximum = 0.1447\n",
      "\n",
      "\n",
      "MEAN COMPACTNESS\n",
      "Mean Compactness Count = 198\n",
      "Mean Compactness Mean = 0.14264777777777776\n",
      "Mean Compactness Standard Deviation = 0.049897601888512416\n",
      "Mean Compactness Minimum = 0.04605\n",
      "Mean Compactness 25% percentile = 0.11019999999999999\n",
      "Mean Compactness 50% percentile = 0.13175\n",
      "Mean Compactness 75% percentile = 0.17220000000000002\n",
      "Mean Compactness Maximum = 0.3114\n",
      "\n",
      "\n",
      "MEAN CONCAVITY\n",
      "Mean Concavity Count = 198\n",
      "Mean Concavity Mean = 0.15624277777777776\n",
      "Mean Concavity Standard Deviation = 0.07057226120534643\n",
      "Mean Concavity Minimum = 0.02398\n",
      "Mean Concavity 25% percentile = 0.10685\n",
      "Mean Concavity 50% percentile = 0.15134999999999998\n",
      "Mean Concavity 75% percentile = 0.2005\n",
      "Mean Concavity Maximum = 0.4268\n",
      "\n",
      "\n",
      "MEAN CONCAVE POINTS\n",
      "Mean Concave Points Count = 198\n",
      "Mean Concave Points Mean = 0.08677560606060604\n",
      "Mean Concave Points Standard Deviation = 0.03387663129061639\n",
      "Mean Concave Points Minimum = 0.02031\n",
      "Mean Concave Points 25% percentile = 0.06367\n",
      "Mean Concave Points 50% percentile = 0.086075\n",
      "Mean Concave Points 75% percentile = 0.103925\n",
      "Mean Concave Points Maximum = 0.2012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1A)\n",
    "\n",
    "#Summary statistics for mean_radius\n",
    "print(\"MEAN RADIUS\")\n",
    "print(f\"Mean Radius Count = {df['mean_radius'].count()}\")\n",
    "print(f\"Mean Radius Mean = {df['mean_radius'].mean()}\")\n",
    "print(f\"Mean Radius Standard Deviation = {df['mean_radius'].std()}\")\n",
    "print(f\"Mean Radius Minimum = {df['mean_radius'].min()}\")\n",
    "print(f\"Mean Radius 25% percentile = {df['mean_radius'].quantile(0.25)}\")\n",
    "print(f\"Mean Radius 50% percentile = {df['mean_radius'].quantile(0.50)}\")\n",
    "print(f\"Mean Radius 75% percentile = {df['mean_radius'].quantile(0.75)}\")\n",
    "print(f\"Mean Radius Maximum = {df['mean_radius'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN TEXTURE\")\n",
    "print(f\"Mean Texture Count = {df['mean_texture'].count()}\")\n",
    "print(f\"Mean Texture Mean = {df['mean_texture'].mean()}\")\n",
    "print(f\"Mean Texture Standard Deviation = {df['mean_texture'].std()}\")\n",
    "print(f\"Mean Texture Minimum = {df['mean_texture'].min()}\")\n",
    "print(f\"Mean Texture 25% percentile = {df['mean_texture'].quantile(0.25)}\")\n",
    "print(f\"Mean Texture 50% percentile = {df['mean_texture'].quantile(0.50)}\")\n",
    "print(f\"Mean Texture 75% percentile = {df['mean_texture'].quantile(0.75)}\")\n",
    "print(f\"Mean Texture Maximum = {df['mean_texture'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN PERIMETER\")\n",
    "print(f\"Mean Perimeter Count = {df['mean_perimeter'].count()}\")\n",
    "print(f\"Mean Perimeter Mean = {df['mean_perimeter'].mean()}\")\n",
    "print(f\"Mean Perimeter Standard Deviation = {df['mean_perimeter'].std()}\")\n",
    "print(f\"Mean Perimeter Minimum = {df['mean_perimeter'].min()}\")\n",
    "print(f\"Mean Perimeter 25% percentile = {df['mean_perimeter'].quantile(0.25)}\")\n",
    "print(f\"Mean Perimeter 50% percentile = {df['mean_perimeter'].quantile(0.50)}\")\n",
    "print(f\"Mean Perimeter 75% percentile = {df['mean_perimeter'].quantile(0.75)}\")\n",
    "print(f\"Mean Perimeter Maximum = {df['mean_perimeter'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN AREA\")\n",
    "print(f\"Mean Area Count = {df['mean_area'].count()}\")\n",
    "print(f\"Mean Area Mean = {df['mean_area'].mean()}\")\n",
    "print(f\"Mean Area Standard Deviation = {df['mean_area'].std()}\")\n",
    "print(f\"Mean Area Minimum = {df['mean_area'].min()}\")\n",
    "print(f\"Mean Area 25% percentile = {df['mean_area'].quantile(0.25)}\")\n",
    "print(f\"Mean Area 50% percentile = {df['mean_area'].quantile(0.50)}\")\n",
    "print(f\"Mean Area 75% percentile = {df['mean_area'].quantile(0.75)}\")\n",
    "print(f\"Mean Area Maximum = {df['mean_area'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN SMOOTHNESS\")\n",
    "print(f\"Mean Smoothness Count = {df['mean_smoothness'].count()}\")\n",
    "print(f\"Mean Smoothness Mean = {df['mean_smoothness'].mean()}\")\n",
    "print(f\"Mean Smoothness Standard Deviation = {df['mean_smoothness'].std()}\")\n",
    "print(f\"Mean Smoothness Minimum = {df['mean_smoothness'].min()}\")\n",
    "print(f\"Mean Smoothness 25% percentile = {df['mean_smoothness'].quantile(0.25)}\")\n",
    "print(f\"Mean Smoothness 50% percentile = {df['mean_smoothness'].quantile(0.50)}\")\n",
    "print(f\"Mean Smoothness 75% percentile = {df['mean_smoothness'].quantile(0.75)}\")\n",
    "print(f\"Mean Smoothness Maximum = {df['mean_smoothness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN COMPACTNESS\")\n",
    "print(f\"Mean Compactness Count = {df['mean_compactness'].count()}\")\n",
    "print(f\"Mean Compactness Mean = {df['mean_compactness'].mean()}\")\n",
    "print(f\"Mean Compactness Standard Deviation = {df['mean_compactness'].std()}\")\n",
    "print(f\"Mean Compactness Minimum = {df['mean_compactness'].min()}\")\n",
    "print(f\"Mean Compactness 25% percentile = {df['mean_compactness'].quantile(0.25)}\")\n",
    "print(f\"Mean Compactness 50% percentile = {df['mean_compactness'].quantile(0.50)}\")\n",
    "print(f\"Mean Compactness 75% percentile = {df['mean_compactness'].quantile(0.75)}\")\n",
    "print(f\"Mean Compactness Maximum = {df['mean_compactness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVITY\")\n",
    "print(f\"Mean Concavity Count = {df['mean_concavity'].count()}\")\n",
    "print(f\"Mean Concavity Mean = {df['mean_concavity'].mean()}\")\n",
    "print(f\"Mean Concavity Standard Deviation = {df['mean_concavity'].std()}\")\n",
    "print(f\"Mean Concavity Minimum = {df['mean_concavity'].min()}\")\n",
    "print(f\"Mean Concavity 25% percentile = {df['mean_concavity'].quantile(0.25)}\")\n",
    "print(f\"Mean Concavity 50% percentile = {df['mean_concavity'].quantile(0.50)}\")\n",
    "print(f\"Mean Concavity 75% percentile = {df['mean_concavity'].quantile(0.75)}\")\n",
    "print(f\"Mean Concavity Maximum = {df['mean_concavity'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVE POINTS\")\n",
    "print(f\"Mean Concave Points Count = {df['mean_concave_points'].count()}\")\n",
    "print(f\"Mean Concave Points Mean = {df['mean_concave_points'].mean()}\")\n",
    "print(f\"Mean Concave Points Standard Deviation = {df['mean_concave_points'].std()}\")\n",
    "print(f\"Mean Concave Points Minimum = {df['mean_concave_points'].min()}\")\n",
    "print(f\"Mean Concave Points 25% percentile = {df['mean_concave_points'].quantile(0.25)}\")\n",
    "print(f\"Mean Concave Points 50% percentile = {df['mean_concave_points'].quantile(0.50)}\")\n",
    "print(f\"Mean Concave Points 75% percentile = {df['mean_concave_points'].quantile(0.75)}\")\n",
    "print(f\"Mean Concave Points Maximum = {df['mean_concave_points'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "id": "3879b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTCOME\n",
      "Outcome Count = 198\n",
      "Outcome unique values are = ['N' 'R']\n",
      "Count of each unique values are = N    151\n",
      "R     47\n",
      "Name: outcome, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 1B)\n",
    "\n",
    "print(\"OUTCOME\")\n",
    "print(f\"Outcome Count = {df['outcome'].count()}\")\n",
    "print(f\"Outcome unique values are = {df['outcome'].unique()}\")\n",
    "print(f\"Count of each unique values are = {df['outcome'].value_counts()}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "id": "9dfb77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1C)\n",
    "df['outcome'].replace('N', 0, inplace=True) \n",
    "df['outcome'].replace('R', 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "id": "2e1e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean_perimeter  se_perimeter\n",
      "mean_perimeter        1.000000      0.609964\n",
      "se_perimeter          0.609964      1.000000\n"
     ]
    }
   ],
   "source": [
    "# Question 1E)\n",
    "print(df[['mean_perimeter','se_perimeter']].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "id": "3df45305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Class for cleaning up data and data manipulation in general\n",
    "class DataManipulation:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def cleanUpData(self):\n",
    "        self.df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    def divideData(self):\n",
    "        \n",
    "        df_negative = self.df[self.df['outcome'] == 0]\n",
    "        df_positive = self.df[self.df['outcome'] == 1]\n",
    "        \n",
    "        \n",
    "        print(len(df_positive))\n",
    "        print(len(df_negative))\n",
    "\n",
    "        df_positive_train = df_positive.sample(n=30)\n",
    "        df_negative_train = df_negative.sample(n=40)\n",
    "\n",
    "        df_positive_test =  df_positive[~df_positive.apply(tuple, axis=1).isin(df_positive_train.apply(tuple, axis=1))]\n",
    "        df_negative_test =  df_negative[~df_negative.apply(tuple, axis=1).isin(df_negative_train.apply(tuple, axis=1))]\n",
    "        \n",
    "        train = pd.concat([df_positive_train, df_negative_train], ignore_index=True)\n",
    "        test = pd.concat([df_positive_test, df_negative_test], ignore_index=True)\n",
    "\n",
    "        train_shuffled = train.sample(frac=1).reset_index(drop=True)\n",
    "        test_shuffled = test.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        return train_shuffled, test_shuffled\n",
    "\n",
    "    \n",
    "    def reqColsFromData(self, cols, data : pd.DataFrame):\n",
    "        finalData = []\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            predictorsArr = []\n",
    "\n",
    "            for col in cols:\n",
    "                predictorsArr.append(row[col])\n",
    "        \n",
    "            finalData.append((predictorsArr, row['outcome']))\n",
    "            \n",
    "        \n",
    "        return finalData\n",
    "    \n",
    "    def performZScoreScaling(self, data):\n",
    "\n",
    "        for x in data:\n",
    "            for index, _ in enumerate(x[0]):\n",
    "                MEAN, STD = self.getMeanStd(index, data)\n",
    "                x[0][index] = (Decimal(x[0][index]) - MEAN) / STD\n",
    "\n",
    "        return data\n",
    "\n",
    "    def getMeanStd(self, col, data):    \n",
    "        dataOfCol = []\n",
    "\n",
    "        for x in data:\n",
    "            dataOfCol.append(Decimal(x[0][col]))\n",
    "\n",
    "        mean = np.mean(dataOfCol)\n",
    "        std = np.std(dataOfCol)\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic regression model Class with all the components required for Logistic regression\n",
    "class LogisticRegression:\n",
    "    \n",
    "    trainingData = None\n",
    "    testData = None\n",
    "    maxNoOfIterations = 1000\n",
    "\n",
    "    def __init__(self, trainingData, testData, thetas, lr, isRegularization):\n",
    "        self.trainingData = trainingData\n",
    "        self.testData = testData\n",
    "        self.thetas = thetas\n",
    "        self.lr = lr\n",
    "        self.isRegularization = isRegularization\n",
    "        \n",
    "        \n",
    "    def getFeatures2D(self, data):\n",
    "        if data != None:\n",
    "            features = [x[0] for x in data]\n",
    "            return features\n",
    "\n",
    "    def getOutputs(self, data):\n",
    "        if data != None:\n",
    "            output = [Decimal(x[1]) for x in data]\n",
    "            return output\n",
    "\n",
    "    def performLogisticRegression(self):\n",
    "        self.iterate()\n",
    "\n",
    "    def computePredictedOutput(self, thetas, data):\n",
    "        predictedOutputs = []\n",
    "\n",
    "        for x in self.getFeatures2D(data):\n",
    "            y = Decimal(thetas[0])\n",
    "\n",
    "            for idx, i in enumerate(x):\n",
    "                y += (Decimal(thetas[idx + 1]) * Decimal(i))\n",
    "\n",
    "            \n",
    "            Y = Decimal(1 / (1 + np.exp(-y) ))\n",
    "            \n",
    "            predictedOutputs.append(Y)\n",
    "\n",
    "        return predictedOutputs\n",
    "    \n",
    "\n",
    "    def calculateGradientDescent(self, B, index,  predictedOutputs, isIntercept):\n",
    "        features = self.getFeatures2D(self.trainingData)\n",
    "        outputs = self.getOutputs(self.trainingData)\n",
    "\n",
    "        dataLen = Decimal(len(features))\n",
    "        \n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(features):\n",
    "\n",
    "            if isIntercept:\n",
    "                result = (predictedOutputs[idx] - outputs[idx])\n",
    "            else:\n",
    "                result = (predictedOutputs[idx] - outputs[idx]) * Decimal(x[index]) \n",
    "\n",
    "\n",
    "            total += result\n",
    "\n",
    "        if self.isRegularization and (not isIntercept):\n",
    "            total += (100 * B) / dataLen # regularization coefficent = 100\n",
    "        \n",
    "        change = (Decimal(self.lr) * total) / dataLen\n",
    "\n",
    "        newB = Decimal(B) - change\n",
    "\n",
    "        \n",
    "        return newB\n",
    "    \n",
    "    def iterate(self):\n",
    "        \n",
    "\n",
    "        for i in range(self.maxNoOfIterations):\n",
    "\n",
    "            predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "\n",
    "            for idx, b in enumerate(self.thetas):\n",
    "                if idx == 0:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, True)\n",
    "                else:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, False)\n",
    "\n",
    "                self.thetas[idx] = newB\n",
    "\n",
    "        \n",
    "        self.printResults()\n",
    "\n",
    "    def calculateCost(self, predictedOutputs, data):\n",
    "        outputs = self.getOutputs(data)\n",
    "        dataLen = len(self.getFeatures2D(data))\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            result = (outputs[idx] * x.log10()) + ((1 - outputs[idx]) * (1 - x).log10())\n",
    "            total += result\n",
    "\n",
    "        return -total/(dataLen)\n",
    "\n",
    "    \n",
    "    def calculateF1Score(self, predictedOutputs, data, threshold):\n",
    "        outputs = self.getOutputs(data)\n",
    "       \n",
    "        roundedPredictedOutputs = []\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            if x < 0.001 :\n",
    "                print(0)\n",
    "            else:\n",
    "                print(x)\n",
    "                \n",
    "            if x > threshold:  \n",
    "                roundedPredictedOutputs.append(1)\n",
    "            else:\n",
    "                roundedPredictedOutputs.append(0)\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "\n",
    "        for idx, x in enumerate(roundedPredictedOutputs):\n",
    "            if x == outputs[idx]:\n",
    "                TP += 1\n",
    "            elif outputs[idx] == 1 and x == 0:\n",
    "                FN += 1\n",
    "            elif outputs[idx] == 0 and x == 1:\n",
    "                FP += 1\n",
    "        \n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            \n",
    "\n",
    "        return f1\n",
    "\n",
    "    def printResults(self):\n",
    "        print(\"The values of the Thetas/ Weights are\")\n",
    "        print(self.thetas)\n",
    "\n",
    "        \n",
    "        # predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "        \n",
    "        # cost = self.calculateCost(predictedOutputs, self.trainingData)\n",
    "        # print(f\"Cost of the Training data is: {cost}\")\n",
    "\n",
    "        # F1Score = self.calculateF1Score(predictedOutputs, self.trainingData, 0.5)\n",
    "        # print(f\"F1 Score of the Training data is: {F1Score}\")\n",
    "\n",
    "        \n",
    "        predictedOutputs = self.computePredictedOutput(self.thetas, self.testData)\n",
    "\n",
    "        cost = self.calculateCost(predictedOutputs, self.testData)\n",
    "        print(f\"Cost of the Test data is: {cost}\")\n",
    "\n",
    "        F1Score = self.calculateF1Score(predictedOutputs, self.testData, 0.6)\n",
    "        print(f\"F1 Score of the Test data is: {F1Score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "id": "5ccbd89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# Getting data ready for logistic regression\n",
    "\n",
    "dm = DataManipulation(df)\n",
    "dm.cleanUpData()\n",
    "\n",
    "train, test = dm.divideData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "id": "33e9abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-4.508912280751136847891779196'), Decimal('0.3291721141121106947903630725')]\n",
      "Cost of the Test data is: 0.01934377809694068996287184508\n",
      "0.05401056577391219663770850042\n",
      "0.07351696109857907452579392264\n",
      "0.9982628442875463168761569276\n",
      "F1 Score of the Test data is: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finalTrain = [([1], 0), ([2], 0), ([3], 0), ([30], 1), ([40], 1)]\n",
    "finalTest = [([5], 0), ([6], 0), ([33], 1)]\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2], 0.1, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr.performLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "id": "ff0d2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-0.005610307867230145718657312348'), Decimal('-0.01759946496532665916266195505')]\n",
      "Cost of the Test data is: 0.2972605282896044329810223131\n",
      "0.4921664588560531207480287838\n",
      "0.5011040723215599812465157491\n",
      "0.4944311083404587638283427931\n",
      "0.4988079248896943542904208857\n",
      "0.4939268735842152891899000480\n",
      "0.4950458891260364201829084067\n",
      "0.4964382766430834603969688118\n",
      "0.4923376861324231511810269968\n",
      "0.4973248475866591197454087554\n",
      "0.4980366319949519379272983266\n",
      "0.5020664070956571396114948959\n",
      "0.4972723679644422941901713227\n",
      "0.5030079029331362132799322965\n",
      "0.4954505651625167992212990964\n",
      "0.4991310268996013323280472928\n",
      "0.5005453598183906687564052592\n",
      "0.4919666000317357063219721668\n",
      "0.4989720042972052165799621886\n",
      "0.4946633564910060699343917405\n",
      "0.4997202251313697918908446416\n",
      "0.4983137557588080592909153789\n",
      "0.4932380837033157997709611847\n",
      "0.4967066316551614152033540504\n",
      "0.4965239552946298576952268558\n",
      "0.4950117529056994918028198584\n",
      "0.4958074757112434887513248975\n",
      "0.4945484222339920198032012928\n",
      "0.5001152637417046754572796168\n",
      "0.5000262633404124040586377105\n",
      "0.5013471855992873401192189183\n",
      "0.4978703916262109966163265963\n",
      "0.4931478522147237643703304994\n",
      "0.4918923374291878580152159103\n",
      "0.4938588999209388540169871128\n",
      "0.4957238046198095579932067596\n",
      "0.4992915630455232843939816969\n",
      "0.4962158586827730529675008721\n",
      "0.4967366248009025041922727252\n",
      "0.4936248184841222313846630774\n",
      "0.4953858428398514339889404504\n",
      "0.4992657406788542556201743075\n",
      "0.4853016477877160742010056565\n",
      "0.4992199029630119013752230469\n",
      "0.4954813011058785318080228310\n",
      "0.4980364012092883516316485983\n",
      "0.4917926436434607408106663897\n",
      "0.4929265092560759047796312048\n",
      "0.4971936500230386704072229784\n",
      "0.4945887311612184162701045878\n",
      "0.4938616431011072348187411313\n",
      "0.4978907283127733397701542610\n",
      "0.4983816649852030958847464459\n",
      "0.4930973613165103934317828612\n",
      "0.4953345453313739940979743481\n",
      "0.4969828262358338078094169086\n",
      "0.4984770898200046935503923138\n",
      "0.4989315914231731108284366965\n",
      "0.4873880982374627050261589779\n",
      "0.4926977560862048288788850705\n",
      "0.4964269091567192499135333531\n",
      "0.4962047055770841299989983402\n",
      "0.4962715557912340029388255203\n",
      "0.4973662777774330443869510580\n",
      "0.4965933493911857466239108772\n",
      "0.4933415664679338698582805356\n",
      "0.4915174904556542719632717756\n",
      "0.4930150832464301183856529467\n",
      "0.4906307260445477994163325631\n",
      "0.4925882272976070895486396985\n",
      "0.4975966570963980132323272650\n",
      "0.4965253908151511903020259728\n",
      "0.4953023233401162314334811325\n",
      "0.4953782114253403890359036023\n",
      "0.4926157111589555452319873656\n",
      "0.4955195068287934055436490733\n",
      "0.4948031219533163902103880347\n",
      "0.4955251350404070453098520982\n",
      "0.4873745444845702226101443614\n",
      "0.4958445214841786958955438729\n",
      "0.4958217982439547389401965525\n",
      "0.4962605354841826249881181584\n",
      "0.4858095757153949745951919678\n",
      "0.4924113032002136163758775510\n",
      "0.4899767256034452438782239722\n",
      "0.4935597406176685768432555303\n",
      "0.4932365108070892665580488519\n",
      "0.4901254232544228498876284750\n",
      "0.4884125476035955149246519797\n",
      "0.4875534926181254315737521234\n",
      "0.4961048599651577577814063751\n",
      "0.4911236005108526292038896865\n",
      "0.4884626429858722466687043030\n",
      "0.4872315081348436697741429579\n",
      "0.4879084896286902077021604595\n",
      "0.4860323581608095441126793228\n",
      "0.4897111608292095254326548827\n",
      "0.4890919546893027797868562598\n",
      "0.4817606148264838022961295837\n",
      "0.4893910093197770039571059731\n",
      "0.4877077570211323302970411489\n",
      "0.4949845597915944075440945827\n",
      "0.4886873631677252953206399694\n",
      "0.4760401199755679792101207397\n",
      "0.4895524476446595283959562319\n",
      "0.4896656649518461585594804805\n",
      "0.4884857823850990700046857700\n",
      "0.4852965536667248109319110073\n",
      "0.4856361608842384960756177990\n",
      "0.4823243924486974443708261883\n",
      "0.4830475584976524660862678145\n",
      "0.4794967725941736592989764335\n",
      "0.4523874709125218461117457738\n",
      "F1 Score of the Test data is: 0.948356807511737\n"
     ]
    }
   ],
   "source": [
    "# Question 2A and 2B\n",
    "tempTrain = dm.reqColsFromData(['mean_area'], train)\n",
    "tempTest = dm.reqColsFromData(['mean_area'], test)\n",
    "\n",
    "finalTrain = dm.performZScoreScaling(tempTrain)\n",
    "finalTest = dm.performZScoreScaling(tempTest)\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2], 0.001, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr.performLogisticRegression()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "id": "b87584c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-0.006194473257853153893943502142'), Decimal('0.04663032616913740685785045269'), Decimal('-0.06209678616000683129784939260'), Decimal('-0.05963852536907768613677054682'), Decimal('-0.1453592931358733910854908892'), Decimal('0.1903103882462416245694625681'), Decimal('0.07066994349012163501886969314'), Decimal('0.2706355391349894290757226772'), Decimal('-0.01049089991545582031579108285'), Decimal('0.08653308700503633139776369011'), Decimal('0.1491900730687416828503245873'), Decimal('0.1983794609429275146722739006'), Decimal('-0.07020875313677999653648502550')]\n",
      "Cost of the Test data is: 0.3100686376171422616066011513\n",
      "0.5246128144942280768681156554\n",
      "0.6301992286915643604944033775\n",
      "0.3718849149056830670364143487\n",
      "0.4805942512578072023699934323\n",
      "0.4752969934256209983677379823\n",
      "0.4762322699601246780307639002\n",
      "0.5289384855987435759254311989\n",
      "0.5101226273212127977156185543\n",
      "0.4393043572584537342734913291\n",
      "0.4376295535974051957773004055\n",
      "0.4659162851610323974564526377\n",
      "0.4691551153818326799313553410\n",
      "0.6349538708658080473781036064\n",
      "0.4229385061092063989982016610\n",
      "0.4163367984050526107797451805\n",
      "0.5512422253609314465109976042\n",
      "0.5612908709756423940170513335\n",
      "0.4261833440394139286999927520\n",
      "0.4375336874196135858354418207\n",
      "0.5256316821609382269092095827\n",
      "0.4668401193350323228514045659\n",
      "0.4151636069248189580779910580\n",
      "0.5330590283185749545217865051\n",
      "0.4278172819820103173001364225\n",
      "0.4839343431097420075918693870\n",
      "0.4696115157184836008561601592\n",
      "0.4762485276979603694763224398\n",
      "0.5553620477128474893578314604\n",
      "0.5005263073029322019973981723\n",
      "0.5396667690530899673025313811\n",
      "0.4700301644559448272910625077\n",
      "0.5642010760442323636480665124\n",
      "0.4790205973833380871675676495\n",
      "0.5459226440731720201041359936\n",
      "0.4573841757714933935842011624\n",
      "0.4653918424753968513755941385\n",
      "0.4989360733764540807972769454\n",
      "0.4647372897556245203337833195\n",
      "0.5013386914017163760272459994\n",
      "0.5058530081546645387964641012\n",
      "0.5429661925277459977214988333\n",
      "0.4741022007052015324379027317\n",
      "0.5283837831323577528513376500\n",
      "0.5223224433446321053113892904\n",
      "0.5743851865122069677627057213\n",
      "0.4777588391060502245006892919\n",
      "0.4803535240510476488757863993\n",
      "0.5233021847925189842366593945\n",
      "0.5069958849776149420448028158\n",
      "0.4892729990857267802761727759\n",
      "0.5418678798030270465563222704\n",
      "0.4548493922705712723850789981\n",
      "0.4454457851733036825470680563\n",
      "0.4814171791987297647428731841\n",
      "0.5923537859295349603344045864\n",
      "0.4972328507752133078672694218\n",
      "0.5638869759052991473009401901\n",
      "0.4660385902191579366247654460\n",
      "0.5349649054747654652670158280\n",
      "0.5697892955907467962808679136\n",
      "0.4841478284078640085509045179\n",
      "0.5183572764907745122804303864\n",
      "0.5142281421842703330087597529\n",
      "0.5120152481387977566671233914\n",
      "0.4112783025169423509768061411\n",
      "0.5661763907674028299297443386\n",
      "0.5191495292592872685771516060\n",
      "0.4524506419473052800267106835\n",
      "0.4876813308232853864441591278\n",
      "0.5769967532046905457292376263\n",
      "0.5699326499075100081925555602\n",
      "0.5071377619619804276043310475\n",
      "0.5262728683696039693677036171\n",
      "0.5242416738602087904989785324\n",
      "0.5121539013620903176881836694\n",
      "0.5663092467338354693248681168\n",
      "0.5024697148478087293042426656\n",
      "0.5132126453881380835723327564\n",
      "0.4788608578407022434892640692\n",
      "0.4777382720201439348253304720\n",
      "0.4795548672948192248762070997\n",
      "0.6123632016939845687464213731\n",
      "0.4476624384199644738695087082\n",
      "0.5903519419038868512011956208\n",
      "0.6915063718352616563162480060\n",
      "0.4367979168455581642312974642\n",
      "0.5062019175780311717789680814\n",
      "0.5210855269916517376439564551\n",
      "0.4495608708079459961511425739\n",
      "0.5182542409851127286966297861\n",
      "0.5654873906990459470081534922\n",
      "0.4658523169331710756786606683\n",
      "0.4307803218350632229012922141\n",
      "0.5440588981804090222502369563\n",
      "0.4498407038704078311184029028\n",
      "0.4938631126919177628966531717\n",
      "0.4377635680470915483596004818\n",
      "0.6067341240985321608241055580\n",
      "0.4621078131691133679444259511\n",
      "0.3617402833121768695034691984\n",
      "0.4910435796895971163506391951\n",
      "0.4417466335200359093408580093\n",
      "0.2910379213343657608335365115\n",
      "0.4174000669680859726343339687\n",
      "0.4875761632518516503080958636\n",
      "0.4142864895089650464342850878\n",
      "0.3867618929342109053507049242\n",
      "0.3998307943981540558972023300\n",
      "0.4182579924121475386362715557\n",
      "0.3483422618851711057410604889\n",
      "0.2415468787270140595133407736\n",
      "0.1326543883618099656372720849\n",
      "F1 Score of the Test data is: 0.923076923076923\n"
     ]
    }
   ],
   "source": [
    "#Question 3A\n",
    "\n",
    "tempTrain = dm.reqColsFromData(['mean_radius',\n",
    "                                'mean_texture',\n",
    "                                'mean_perimeter',\n",
    "                                'mean_area',\n",
    "                                'mean_smoothness',\n",
    "                                'mean_compactness',\n",
    "                                'mean_concavity',\n",
    "                                'mean_concave_points',\n",
    "                                'mean_fractal_dimension',\n",
    "                                'se_perimeter',\n",
    "                                'se_texture',\n",
    "                                'se_area'], train)\n",
    "tempTest = dm.reqColsFromData(['mean_radius',\n",
    "                                'mean_texture',\n",
    "                                'mean_perimeter',\n",
    "                                'mean_area',\n",
    "                                'mean_smoothness',\n",
    "                                'mean_compactness',\n",
    "                                'mean_concavity',\n",
    "                                'mean_concave_points',\n",
    "                                'mean_fractal_dimension',\n",
    "                                'se_perimeter',\n",
    "                                'se_texture',\n",
    "                                'se_area'], test)\n",
    "\n",
    "\n",
    "finalTrain = dm.performZScoreScaling(tempTrain)\n",
    "finalTest = dm.performZScoreScaling(tempTest)\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2, 0.1, 0.1, 0.0, 0.2, 0.1, 0.3, 0.0, 0.1, 0.2, 0.3, 0.0], 0.001, False) \n",
    "lr.performLogisticRegression() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b87798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
