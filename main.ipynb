{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "6c89cfe1-6927-44c6-8e2d-373f3f5bcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('Cancer_dataset1.csv')\n",
    "\n",
    "for i in df.outcome:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "8678835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN RADIUS\n",
      "Mean Radius Count = 194\n",
      "Mean Radius Mean = 17.412061855670103\n",
      "Mean Radius Standard Deviation = 3.1571814471858555\n",
      "Mean Radius Minimum = 10.95\n",
      "Mean Radius 25% percentile = 15.0525\n",
      "Mean Radius 50% percentile = 17.28\n",
      "Mean Radius 75% percentile = 19.58\n",
      "Mean Radius Maximum = 27.22\n",
      "\n",
      "\n",
      "MEAN TEXTURE\n",
      "Mean Texture Count = 194\n",
      "Mean Texture Mean = 22.3190206185567\n",
      "Mean Texture Standard Deviation = 4.283068191040899\n",
      "Mean Texture Minimum = 10.38\n",
      "Mean Texture 25% percentile = 19.517500000000002\n",
      "Mean Texture 50% percentile = 21.795\n",
      "Mean Texture 75% percentile = 24.655\n",
      "Mean Texture Maximum = 39.28\n",
      "\n",
      "\n",
      "MEAN PERIMETER\n",
      "Mean Perimeter Count = 198\n",
      "Mean Perimeter Mean = 114.85656565656565\n",
      "Mean Perimeter Standard Deviation = 21.383401559552883\n",
      "Mean Perimeter Minimum = 71.9\n",
      "Mean Perimeter 25% percentile = 98.16\n",
      "Mean Perimeter 50% percentile = 113.7\n",
      "Mean Perimeter 75% percentile = 129.64999999999998\n",
      "Mean Perimeter Maximum = 182.1\n",
      "\n",
      "\n",
      "MEAN AREA\n",
      "Mean Area Count = 198\n",
      "Mean Area Mean = 970.0409090909089\n",
      "Mean Area Standard Deviation = 352.14921516208284\n",
      "Mean Area Minimum = 361.6\n",
      "Mean Area 25% percentile = 702.525\n",
      "Mean Area 50% percentile = 929.0999999999999\n",
      "Mean Area 75% percentile = 1193.5\n",
      "Mean Area Maximum = 2250.0\n",
      "\n",
      "\n",
      "MEAN SMOOTHNESS\n",
      "Mean Smoothness Count = 198\n",
      "Mean Smoothness Mean = 0.10268141414141414\n",
      "Mean Smoothness Standard Deviation = 0.012522431569239916\n",
      "Mean Smoothness Minimum = 0.07497\n",
      "Mean Smoothness 25% percentile = 0.0939\n",
      "Mean Smoothness 50% percentile = 0.10189999999999999\n",
      "Mean Smoothness 75% percentile = 0.110975\n",
      "Mean Smoothness Maximum = 0.1447\n",
      "\n",
      "\n",
      "MEAN COMPACTNESS\n",
      "Mean Compactness Count = 198\n",
      "Mean Compactness Mean = 0.14264777777777776\n",
      "Mean Compactness Standard Deviation = 0.049897601888512416\n",
      "Mean Compactness Minimum = 0.04605\n",
      "Mean Compactness 25% percentile = 0.11019999999999999\n",
      "Mean Compactness 50% percentile = 0.13175\n",
      "Mean Compactness 75% percentile = 0.17220000000000002\n",
      "Mean Compactness Maximum = 0.3114\n",
      "\n",
      "\n",
      "MEAN CONCAVITY\n",
      "Mean Concavity Count = 198\n",
      "Mean Concavity Mean = 0.15624277777777776\n",
      "Mean Concavity Standard Deviation = 0.07057226120534643\n",
      "Mean Concavity Minimum = 0.02398\n",
      "Mean Concavity 25% percentile = 0.10685\n",
      "Mean Concavity 50% percentile = 0.15134999999999998\n",
      "Mean Concavity 75% percentile = 0.2005\n",
      "Mean Concavity Maximum = 0.4268\n",
      "\n",
      "\n",
      "MEAN CONCAVE POINTS\n",
      "Mean Concave Points Count = 198\n",
      "Mean Concave Points Mean = 0.08677560606060604\n",
      "Mean Concave Points Standard Deviation = 0.03387663129061639\n",
      "Mean Concave Points Minimum = 0.02031\n",
      "Mean Concave Points 25% percentile = 0.06367\n",
      "Mean Concave Points 50% percentile = 0.086075\n",
      "Mean Concave Points 75% percentile = 0.103925\n",
      "Mean Concave Points Maximum = 0.2012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1A)\n",
    "\n",
    "#Summary statistics for mean_radius\n",
    "print(\"MEAN RADIUS\")\n",
    "print(f\"Mean Radius Count = {df['mean_radius'].count()}\")\n",
    "print(f\"Mean Radius Mean = {df['mean_radius'].mean()}\")\n",
    "print(f\"Mean Radius Standard Deviation = {df['mean_radius'].std()}\")\n",
    "print(f\"Mean Radius Minimum = {df['mean_radius'].min()}\")\n",
    "print(f\"Mean Radius 25% percentile = {df['mean_radius'].quantile(0.25)}\")\n",
    "print(f\"Mean Radius 50% percentile = {df['mean_radius'].quantile(0.50)}\")\n",
    "print(f\"Mean Radius 75% percentile = {df['mean_radius'].quantile(0.75)}\")\n",
    "print(f\"Mean Radius Maximum = {df['mean_radius'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN TEXTURE\")\n",
    "print(f\"Mean Texture Count = {df['mean_texture'].count()}\")\n",
    "print(f\"Mean Texture Mean = {df['mean_texture'].mean()}\")\n",
    "print(f\"Mean Texture Standard Deviation = {df['mean_texture'].std()}\")\n",
    "print(f\"Mean Texture Minimum = {df['mean_texture'].min()}\")\n",
    "print(f\"Mean Texture 25% percentile = {df['mean_texture'].quantile(0.25)}\")\n",
    "print(f\"Mean Texture 50% percentile = {df['mean_texture'].quantile(0.50)}\")\n",
    "print(f\"Mean Texture 75% percentile = {df['mean_texture'].quantile(0.75)}\")\n",
    "print(f\"Mean Texture Maximum = {df['mean_texture'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN PERIMETER\")\n",
    "print(f\"Mean Perimeter Count = {df['mean_perimeter'].count()}\")\n",
    "print(f\"Mean Perimeter Mean = {df['mean_perimeter'].mean()}\")\n",
    "print(f\"Mean Perimeter Standard Deviation = {df['mean_perimeter'].std()}\")\n",
    "print(f\"Mean Perimeter Minimum = {df['mean_perimeter'].min()}\")\n",
    "print(f\"Mean Perimeter 25% percentile = {df['mean_perimeter'].quantile(0.25)}\")\n",
    "print(f\"Mean Perimeter 50% percentile = {df['mean_perimeter'].quantile(0.50)}\")\n",
    "print(f\"Mean Perimeter 75% percentile = {df['mean_perimeter'].quantile(0.75)}\")\n",
    "print(f\"Mean Perimeter Maximum = {df['mean_perimeter'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN AREA\")\n",
    "print(f\"Mean Area Count = {df['mean_area'].count()}\")\n",
    "print(f\"Mean Area Mean = {df['mean_area'].mean()}\")\n",
    "print(f\"Mean Area Standard Deviation = {df['mean_area'].std()}\")\n",
    "print(f\"Mean Area Minimum = {df['mean_area'].min()}\")\n",
    "print(f\"Mean Area 25% percentile = {df['mean_area'].quantile(0.25)}\")\n",
    "print(f\"Mean Area 50% percentile = {df['mean_area'].quantile(0.50)}\")\n",
    "print(f\"Mean Area 75% percentile = {df['mean_area'].quantile(0.75)}\")\n",
    "print(f\"Mean Area Maximum = {df['mean_area'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN SMOOTHNESS\")\n",
    "print(f\"Mean Smoothness Count = {df['mean_smoothness'].count()}\")\n",
    "print(f\"Mean Smoothness Mean = {df['mean_smoothness'].mean()}\")\n",
    "print(f\"Mean Smoothness Standard Deviation = {df['mean_smoothness'].std()}\")\n",
    "print(f\"Mean Smoothness Minimum = {df['mean_smoothness'].min()}\")\n",
    "print(f\"Mean Smoothness 25% percentile = {df['mean_smoothness'].quantile(0.25)}\")\n",
    "print(f\"Mean Smoothness 50% percentile = {df['mean_smoothness'].quantile(0.50)}\")\n",
    "print(f\"Mean Smoothness 75% percentile = {df['mean_smoothness'].quantile(0.75)}\")\n",
    "print(f\"Mean Smoothness Maximum = {df['mean_smoothness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN COMPACTNESS\")\n",
    "print(f\"Mean Compactness Count = {df['mean_compactness'].count()}\")\n",
    "print(f\"Mean Compactness Mean = {df['mean_compactness'].mean()}\")\n",
    "print(f\"Mean Compactness Standard Deviation = {df['mean_compactness'].std()}\")\n",
    "print(f\"Mean Compactness Minimum = {df['mean_compactness'].min()}\")\n",
    "print(f\"Mean Compactness 25% percentile = {df['mean_compactness'].quantile(0.25)}\")\n",
    "print(f\"Mean Compactness 50% percentile = {df['mean_compactness'].quantile(0.50)}\")\n",
    "print(f\"Mean Compactness 75% percentile = {df['mean_compactness'].quantile(0.75)}\")\n",
    "print(f\"Mean Compactness Maximum = {df['mean_compactness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVITY\")\n",
    "print(f\"Mean Concavity Count = {df['mean_concavity'].count()}\")\n",
    "print(f\"Mean Concavity Mean = {df['mean_concavity'].mean()}\")\n",
    "print(f\"Mean Concavity Standard Deviation = {df['mean_concavity'].std()}\")\n",
    "print(f\"Mean Concavity Minimum = {df['mean_concavity'].min()}\")\n",
    "print(f\"Mean Concavity 25% percentile = {df['mean_concavity'].quantile(0.25)}\")\n",
    "print(f\"Mean Concavity 50% percentile = {df['mean_concavity'].quantile(0.50)}\")\n",
    "print(f\"Mean Concavity 75% percentile = {df['mean_concavity'].quantile(0.75)}\")\n",
    "print(f\"Mean Concavity Maximum = {df['mean_concavity'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVE POINTS\")\n",
    "print(f\"Mean Concave Points Count = {df['mean_concave_points'].count()}\")\n",
    "print(f\"Mean Concave Points Mean = {df['mean_concave_points'].mean()}\")\n",
    "print(f\"Mean Concave Points Standard Deviation = {df['mean_concave_points'].std()}\")\n",
    "print(f\"Mean Concave Points Minimum = {df['mean_concave_points'].min()}\")\n",
    "print(f\"Mean Concave Points 25% percentile = {df['mean_concave_points'].quantile(0.25)}\")\n",
    "print(f\"Mean Concave Points 50% percentile = {df['mean_concave_points'].quantile(0.50)}\")\n",
    "print(f\"Mean Concave Points 75% percentile = {df['mean_concave_points'].quantile(0.75)}\")\n",
    "print(f\"Mean Concave Points Maximum = {df['mean_concave_points'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "3879b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTCOME\n",
      "Outcome Count = 198\n",
      "Outcome unique values are = ['N' 'R']\n",
      "Count of each unique values are = N    151\n",
      "R     47\n",
      "Name: outcome, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 1B)\n",
    "\n",
    "print(\"OUTCOME\")\n",
    "print(f\"Outcome Count = {df['outcome'].count()}\")\n",
    "print(f\"Outcome unique values are = {df['outcome'].unique()}\")\n",
    "print(f\"Count of each unique values are = {df['outcome'].value_counts()}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "9dfb77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1C)\n",
    "df['outcome'].replace('N', 0, inplace=True) \n",
    "df['outcome'].replace('R', 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "2e1e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean_perimeter  se_perimeter\n",
      "mean_perimeter        1.000000      0.609964\n",
      "se_perimeter          0.609964      1.000000\n"
     ]
    }
   ],
   "source": [
    "# Question 1E)\n",
    "print(df[['mean_perimeter','se_perimeter']].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df45305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Class for cleaning up data and data manipulation in general\n",
    "class DataManipulation:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def cleanUpData(self):\n",
    "        self.df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    def divideData(self):\n",
    "        \n",
    "        df_negative = self.df[self.df['outcome'] == 0]\n",
    "        df_positive = self.df[self.df['outcome'] == 1]\n",
    "        \n",
    "        \n",
    "        print(len(df_positive))\n",
    "        print(len(df_negative))\n",
    "\n",
    "        df_positive_train = df_positive.sample(n=35)\n",
    "        df_negative_train = df_negative.sample(n=60)\n",
    "\n",
    "        df_positive_test =  df_positive[~df_positive.apply(tuple, axis=1).isin(df_positive_train.apply(tuple, axis=1))]\n",
    "        df_negative_test =  df_negative[~df_negative.apply(tuple, axis=1).isin(df_negative_train.apply(tuple, axis=1))]\n",
    "        \n",
    "        train = pd.concat([df_positive_train, df_negative_train], ignore_index=True)\n",
    "        test = pd.concat([df_positive_test, df_negative_test], ignore_index=True)\n",
    "\n",
    "        train_shuffled = train.sample(frac=1).reset_index(drop=True)\n",
    "        test_shuffled = test.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        return train_shuffled, test_shuffled\n",
    "\n",
    "    \n",
    "    def reqColsFromData(self, cols, data : pd.DataFrame):\n",
    "        finalData = []\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            predictorsArr = []\n",
    "\n",
    "            for col in cols:\n",
    "                predictorsArr.append(row[col])\n",
    "        \n",
    "            finalData.append((predictorsArr, row['outcome']))\n",
    "            \n",
    "        \n",
    "        return finalData\n",
    "    \n",
    "    def performZScoreScaling(self, data):\n",
    "\n",
    "        for x in data:\n",
    "            for index, _ in enumerate(x[0]):\n",
    "                MEAN, STD = self.getMeanStd(index, data)\n",
    "                x[0][index] = (Decimal(x[0][index]) - MEAN) / STD\n",
    "\n",
    "        return data\n",
    "\n",
    "    def getMeanStd(self, col, data):    \n",
    "        dataOfCol = []\n",
    "\n",
    "        for x in data:\n",
    "            dataOfCol.append(Decimal(x[0][col]))\n",
    "\n",
    "        mean = np.mean(dataOfCol)\n",
    "        std = np.std(dataOfCol)\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic regression model Class with all the components required for Logistic regression\n",
    "class LogisticRegression:\n",
    "    \n",
    "    trainingData = None\n",
    "    testData = None\n",
    "    maxNoOfIterations = 1000\n",
    "\n",
    "    def __init__(self, trainingData, testData, thetas, lr, isRegularization):\n",
    "        self.trainingData = trainingData\n",
    "        self.testData = testData\n",
    "        self.thetas = thetas\n",
    "        self.lr = lr\n",
    "        self.isRegularization = isRegularization\n",
    "        \n",
    "        \n",
    "    def getFeatures2D(self, data):\n",
    "        if data != None:\n",
    "            features = [x[0] for x in data]\n",
    "            return features\n",
    "\n",
    "    def getOutputs(self, data):\n",
    "        if data != None:\n",
    "            output = [Decimal(x[1]) for x in data]\n",
    "            return output\n",
    "\n",
    "    def performLogisticRegression(self):\n",
    "        self.iterate()\n",
    "\n",
    "    def computePredictedOutput(self, thetas, data):\n",
    "        predictedOutputs = []\n",
    "\n",
    "        for x in self.getFeatures2D(data):\n",
    "            y = Decimal(thetas[0])\n",
    "\n",
    "            for idx, i in enumerate(x):\n",
    "                y += (Decimal(thetas[idx + 1]) * Decimal(i))\n",
    "\n",
    "            \n",
    "            Y = Decimal(1 / (1 + np.exp(-y) ))\n",
    "            \n",
    "            predictedOutputs.append(Y)\n",
    "\n",
    "        return predictedOutputs\n",
    "    \n",
    "\n",
    "    def calculateGradientDescent(self, B, index,  predictedOutputs, isIntercept):\n",
    "        features = self.getFeatures2D(self.trainingData)\n",
    "        outputs = self.getOutputs(self.trainingData)\n",
    "\n",
    "        dataLen = Decimal(len(features))\n",
    "        \n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(features):\n",
    "\n",
    "            if isIntercept:\n",
    "                result = (predictedOutputs[idx] - outputs[idx])\n",
    "            else:\n",
    "                result = (predictedOutputs[idx] - outputs[idx]) * Decimal(x[index]) \n",
    "\n",
    "\n",
    "            total += result\n",
    "\n",
    "        if self.isRegularization and (not isIntercept):\n",
    "            total += (100 * B) / dataLen # regularization coefficent = 100\n",
    "        \n",
    "        change = (Decimal(self.lr) * total) / dataLen\n",
    "\n",
    "        newB = Decimal(B) - change\n",
    "\n",
    "        \n",
    "        return newB\n",
    "    \n",
    "    def iterate(self):\n",
    "        \n",
    "\n",
    "        for i in range(self.maxNoOfIterations):\n",
    "\n",
    "            predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "\n",
    "            for idx, b in enumerate(self.thetas):\n",
    "                if idx == 0:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, True)\n",
    "                else:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, False)\n",
    "\n",
    "                self.thetas[idx] = newB\n",
    "\n",
    "        \n",
    "        self.printResults()\n",
    "\n",
    "    def calculateCost(self, predictedOutputs, data):\n",
    "        outputs = self.getOutputs(data)\n",
    "        dataLen = len(self.getFeatures2D(data))\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            result = (outputs[idx] * x.log10()) + ((1 - outputs[idx]) * (1 - x).log10())\n",
    "            total += result\n",
    "\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    def calculateF1Score(self, predictedOutputs, data, threshold):\n",
    "        outputs = self.getOutputs(data)\n",
    "       \n",
    "        roundedPredictedOutputs = []\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            if x < 0.001 :\n",
    "                print(0)\n",
    "            else:\n",
    "                print(x)\n",
    "                \n",
    "            if x > threshold:  \n",
    "                roundedPredictedOutputs.append(1)\n",
    "            else:\n",
    "                roundedPredictedOutputs.append(0)\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "\n",
    "        for idx, x in enumerate(roundedPredictedOutputs):\n",
    "            if x == outputs[idx]:\n",
    "                TP += 1\n",
    "            elif outputs[idx] == 1 and x == 0:\n",
    "                FN += 1\n",
    "            elif outputs[idx] == 0 and x == 1:\n",
    "                FP += 1\n",
    "        \n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            \n",
    "\n",
    "        return f1\n",
    "\n",
    "    def printResults(self):\n",
    "        print(\"The values of the Thetas/ Weights are\")\n",
    "        print(self.thetas)\n",
    "\n",
    "        \n",
    "        # predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "        \n",
    "        # cost = self.calculateCost(predictedOutputs, self.trainingData)\n",
    "        # print(f\"Cost of the Training data is: {cost}\")\n",
    "\n",
    "        # F1Score = self.calculateF1Score(predictedOutputs, self.trainingData, 0.5)\n",
    "        # print(f\"F1 Score of the Training data is: {F1Score}\")\n",
    "\n",
    "        \n",
    "        predictedOutputs = self.computePredictedOutput(self.thetas, self.testData)\n",
    "\n",
    "        cost = self.calculateCost(predictedOutputs, self.testData)\n",
    "        print(f\"Cost of the Test data is: {cost}\")\n",
    "\n",
    "        F1Score = self.calculateF1Score(predictedOutputs, self.testData, 0.5)\n",
    "        print(f\"F1 Score of the Test data is: {F1Score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "5ccbd89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# Getting data ready for logistic regression\n",
    "\n",
    "dm = DataManipulation(df)\n",
    "dm.cleanUpData()\n",
    "\n",
    "train, test = dm.divideData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "33e9abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-4.508912280751136847891779196'), Decimal('0.3291721141121106947903630725')]\n",
      "Cost of the Test data is: 0\n",
      "0.05401056577391219663770850042\n",
      "0.07351696109857907452579392264\n",
      "0.9982628442875463168761569276\n",
      "F1 Score of the Test data is: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finalTrain = [([1], 0), ([2], 0), ([3], 0), ([30], 1), ([40], 1)]\n",
    "finalTest = [([5], 0), ([6], 0), ([33], 1)]\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2], 0.1, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr.performLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "ff0d2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-0.05037437471371817164356042267'), Decimal('-0.06216078540264910223096152140')]\n",
      "Cost of the Test data is: 0\n",
      "0.4854820649974981386527081521\n",
      "0.4854087251431598005003342952\n",
      "0.4633850685432906101089997831\n",
      "0.4752199320980442078897313002\n",
      "0.4926922604662148711839102047\n",
      "0.4965853754982734544300919946\n",
      "0.4923352775092534280696497090\n",
      "0.4810227024489629688343884698\n",
      "0.4858075567303258407356556724\n",
      "0.4925278950400215432977235311\n",
      "0.4846409563244845765511638008\n",
      "0.4531397809582375381794547551\n",
      "0.4783187619680027239961231657\n",
      "0.4618576083791821358891068592\n",
      "0.4713262996159552493477298942\n",
      "0.4900668560247119362416617060\n",
      "0.4779443520161367899898050798\n",
      "0.4831735498882953874109069236\n",
      "0.4884574322777256435313017286\n",
      "0.4732406042302296162711522663\n",
      "0.4820906733233852120921679606\n",
      "0.4842644231609338109486830417\n",
      "0.4829431518136930271483855572\n",
      "0.4815558688946947133847524228\n",
      "0.4817593831282290065892410364\n",
      "0.4759254017262327220302011715\n",
      "0.4711234135366205386902582769\n",
      "0.4763996120950240656908337932\n",
      "0.4715261306211962017366320615\n",
      "0.4768014105790748755831057486\n",
      "0.4834042972871050846997945547\n",
      "0.4766228579005618558811113041\n",
      "0.4773119093844611207413876751\n",
      "0.4767362431920972637539707572\n",
      "0.4713218595558528309924503017\n",
      "0.4710594062136313149858293252\n",
      "0.4737986649692898963215116145\n",
      "0.4745566125710238990613553477\n",
      "0.4756528625974341429121269318\n",
      "0.4623441212337566851534386846\n",
      "0.4783181137296654184552757638\n",
      "0.4773422311760375411981316519\n",
      "0.4797808369598175084743726452\n",
      "0.4707813172370593477366575309\n",
      "0.4735184785654536044410649174\n",
      "0.4812909918075563996327131473\n",
      "0.4724616920630684704186549464\n",
      "0.4563735902157248943452667559\n",
      "0.4666771133042221394929945919\n",
      "0.4813701443518031634756893166\n",
      "0.4686754423903046158786794178\n",
      "0.4735541679045089826319641556\n",
      "0.4670209343810448809193742653\n",
      "0.4664092310308738552815959597\n",
      "0.4687913097412661736718416029\n",
      "0.4827411831367221771241319412\n",
      "0.4674966702045381266714769151\n",
      "0.4710720613705067333035805953\n",
      "0.4601506490101248755472356840\n",
      "0.4652031485474443712826147690\n",
      "0.4622535462197949016864709474\n",
      "0.4726336834810645753648762095\n",
      "0.4765495812245647922541801076\n",
      "0.4715191842265856634928504915\n",
      "0.4646117776743934364695126278\n",
      "0.4663316855664079519964497297\n",
      "0.4470255258441523044915030510\n",
      "0.4657483116076277450919719653\n",
      "0.4641685750642279281091699225\n",
      "0.4578160609748337612450496551\n",
      "0.4514853228745439664151354143\n",
      "0.4473366163738325960274464483\n",
      "0.4678731292448317935362592619\n",
      "0.4412449524742170115106952249\n",
      "0.4509167735139172045781452069\n",
      "0.4551630451668920629730090059\n",
      "0.4313371325937879122177533614\n",
      "0.4489642622374526761757444777\n",
      "0.4452805777264857487314032709\n",
      "0.4233323761176000403252158574\n",
      "0.4364367136194182022044886709\n",
      "0.4348591604785420814589577198\n",
      "0.4168714786382224285036999937\n",
      "0.4281512848629050356843831867\n",
      "0.3828054286265390565740425485\n",
      "0.4008229341757821037075567899\n",
      "0.3730075573580259019035461790\n",
      "F1 Score of the Test data is: 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "# Question 2A and 2B\n",
    "tempTrain = dm.reqColsFromData(['mean_texture'], train)\n",
    "tempTest = dm.reqColsFromData(['mean_texture'], test)\n",
    "\n",
    "finalTrain = dm.performZScoreScaling(tempTrain)\n",
    "finalTest = dm.performZScoreScaling(tempTest)\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2], 0.001, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr.performLogisticRegression()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "b87584c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-0.04850494210462358757146978128'), Decimal('0.04136701923358783555714855754'), Decimal('-0.1033983039958369345124726867'), Decimal('-0.06108828766582101708492309794'), Decimal('-0.1120640182328727487779769231'), Decimal('0.1847964489519826110727281204'), Decimal('0.07312095787657902697800284608'), Decimal('0.2784706557928171702333264287'), Decimal('-0.005418729791340483463593059391'), Decimal('0.08631455418762439044643222856'), Decimal('0.1151192573385706763919046061'), Decimal('0.1640740819254436966354805113'), Decimal('-0.08350188470013975782700589266')]\n",
      "Cost of the Test data is: 0\n",
      "0.5510796037197536991707743789\n",
      "0.3502775358530267129671827093\n",
      "0.4783416290976746601945397294\n",
      "0.4699496305373944708354087119\n",
      "0.6310572658782214736704506996\n",
      "0.5082626802901071398213434817\n",
      "0.5247790517144551464780317530\n",
      "0.5759128204679271774148660687\n",
      "0.5262351989672237374250013959\n",
      "0.5728832445130432817035451593\n",
      "0.4489168704475788822315587394\n",
      "0.4003328782620375017705946169\n",
      "0.4761986352205663030729043944\n",
      "0.5781962966461629746981347360\n",
      "0.4238201785493120473879731167\n",
      "0.4745231525435070511214078699\n",
      "0.4461801026522703107627505632\n",
      "0.4579465887052065341510295584\n",
      "0.4274078142724183242695309362\n",
      "0.4809722535784153394976798335\n",
      "0.5140792645434166044461821211\n",
      "0.4776735033716652994111214031\n",
      "0.5127343364524141834336402413\n",
      "0.4638405667816308211805443648\n",
      "0.6486504049754783205971460324\n",
      "0.5559256776603841271036780347\n",
      "0.5425921784480411956207885025\n",
      "0.4240610141819891552978956851\n",
      "0.4186406768533973837922610837\n",
      "0.4402195924158826488440324613\n",
      "0.4700886453005074290027217744\n",
      "0.5644848976793871138793704664\n",
      "0.4880887407308693623287200089\n",
      "0.4400269919952158417224000305\n",
      "0.4940177181540260655336820480\n",
      "0.4293740957102809025576618088\n",
      "0.6428772145530764831127914680\n",
      "0.4084480768305287186640319258\n",
      "0.4698280169129474467697920340\n",
      "0.4610802163157765277094510824\n",
      "0.4693451718285304967021760086\n",
      "0.4316989295296274476638601368\n",
      "0.4278923785350265147587718489\n",
      "0.5195417578168973358783729722\n",
      "0.4839086651218893488962568842\n",
      "0.5271767923831335395104635606\n",
      "0.4697950285059285981872517359\n",
      "0.4641858513417884591342195067\n",
      "0.4913187345008531891690688683\n",
      "0.4591242478981254398335801650\n",
      "0.4984996481571645224290830189\n",
      "0.4942724778455400133656523135\n",
      "0.5544521950601045784054949463\n",
      "0.4492565586305755674147128853\n",
      "0.4789714898642018871713410427\n",
      "0.4889156303990470104133728807\n",
      "0.4490723153424356572811508285\n",
      "0.4553561913615944963843512888\n",
      "0.4042844201427979571841028323\n",
      "0.4815538277591239471712361852\n",
      "0.4771521576576257921413881752\n",
      "0.4331954355523892868473587580\n",
      "0.4890136630446659892115317064\n",
      "0.3874972960990465038900372002\n",
      "0.3961539223676540043242402200\n",
      "0.4785190353595842984184232401\n",
      "0.3773637524932813927908213667\n",
      "0.4018239991689288751036572728\n",
      "0.4129851996407504978875112117\n",
      "0.4681433207796731269779859380\n",
      "0.4377739910437869857131424927\n",
      "0.4022123066853816237352014835\n",
      "0.4074718094928838278453306392\n",
      "0.3885105212130693612465002426\n",
      "0.4530475529403783217649605811\n",
      "0.3158670516381857798052586885\n",
      "0.3530868661421898339711040121\n",
      "0.3724745480933686380529574721\n",
      "0.3281188006970121425871967081\n",
      "0.3080202385858091919304161818\n",
      "0.3500405404500030549851191934\n",
      "0.3175185283558268607060752712\n",
      "0.2976349145082477109755159372\n",
      "0.2322884638681769859599428630\n",
      "0.1363159551248924564562518026\n",
      "0.1355400512481481419945019944\n",
      "0.08927479948761105860841353426\n",
      "F1 Score of the Test data is: 0.855263157894737\n"
     ]
    }
   ],
   "source": [
    "#Question 3A\n",
    "\n",
    "tempTrain = dm.reqColsFromData(['mean_radius',\n",
    "                                'mean_texture',\n",
    "                                'mean_perimeter',\n",
    "                                'mean_area',\n",
    "                                'mean_smoothness',\n",
    "                                'mean_compactness',\n",
    "                                'mean_concavity',\n",
    "                                'mean_concave_points',\n",
    "                                'mean_fractal_dimension',\n",
    "                                'se_perimeter',\n",
    "                                'se_texture',\n",
    "                                'se_area'], train)\n",
    "tempTest = dm.reqColsFromData(['mean_radius',\n",
    "                                'mean_texture',\n",
    "                                'mean_perimeter',\n",
    "                                'mean_area',\n",
    "                                'mean_smoothness',\n",
    "                                'mean_compactness',\n",
    "                                'mean_concavity',\n",
    "                                'mean_concave_points',\n",
    "                                'mean_fractal_dimension',\n",
    "                                'se_perimeter',\n",
    "                                'se_texture',\n",
    "                                'se_area'], test)\n",
    "\n",
    "\n",
    "finalTrain = dm.performZScoreScaling(tempTrain)\n",
    "finalTest = dm.performZScoreScaling(tempTest)\n",
    "\n",
    "lr = LogisticRegression(finalTrain, finalTest, [0.1, 0.2, 0.1, 0.1, 0.0, 0.2, 0.1, 0.3, 0.0, 0.1, 0.2, 0.3, 0.0], 0.001, False) \n",
    "lr.performLogisticRegression() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b87798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
