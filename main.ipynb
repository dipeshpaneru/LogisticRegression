{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "6c89cfe1-6927-44c6-8e2d-373f3f5bcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "R\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "R\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('Cancer_dataset1.csv')\n",
    "\n",
    "for i in df.outcome:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "8678835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN RADIUS\n",
      "Mean Radius Count = 194\n",
      "Mean Radius Mean = 17.412061855670103\n",
      "Mean Radius Standard Deviation = 3.1571814471858555\n",
      "Mean Radius Minimum = 10.95\n",
      "Mean Radius 25% percentile = 15.0525\n",
      "Mean Radius 50% percentile = 17.28\n",
      "Mean Radius 75% percentile = 19.58\n",
      "Mean Radius Maximum = 27.22\n",
      "\n",
      "\n",
      "MEAN TEXTURE\n",
      "Mean Texture Count = 194\n",
      "Mean Texture Mean = 22.3190206185567\n",
      "Mean Texture Standard Deviation = 4.283068191040899\n",
      "Mean Texture Minimum = 10.38\n",
      "Mean Texture 25% percentile = 19.517500000000002\n",
      "Mean Texture 50% percentile = 21.795\n",
      "Mean Texture 75% percentile = 24.655\n",
      "Mean Texture Maximum = 39.28\n",
      "\n",
      "\n",
      "MEAN PERIMETER\n",
      "Mean Perimeter Count = 198\n",
      "Mean Perimeter Mean = 114.85656565656565\n",
      "Mean Perimeter Standard Deviation = 21.383401559552883\n",
      "Mean Perimeter Minimum = 71.9\n",
      "Mean Perimeter 25% percentile = 98.16\n",
      "Mean Perimeter 50% percentile = 113.7\n",
      "Mean Perimeter 75% percentile = 129.64999999999998\n",
      "Mean Perimeter Maximum = 182.1\n",
      "\n",
      "\n",
      "MEAN AREA\n",
      "Mean Area Count = 198\n",
      "Mean Area Mean = 970.0409090909089\n",
      "Mean Area Standard Deviation = 352.14921516208284\n",
      "Mean Area Minimum = 361.6\n",
      "Mean Area 25% percentile = 702.525\n",
      "Mean Area 50% percentile = 929.0999999999999\n",
      "Mean Area 75% percentile = 1193.5\n",
      "Mean Area Maximum = 2250.0\n",
      "\n",
      "\n",
      "MEAN SMOOTHNESS\n",
      "Mean Smoothness Count = 198\n",
      "Mean Smoothness Mean = 0.10268141414141414\n",
      "Mean Smoothness Standard Deviation = 0.012522431569239916\n",
      "Mean Smoothness Minimum = 0.07497\n",
      "Mean Smoothness 25% percentile = 0.0939\n",
      "Mean Smoothness 50% percentile = 0.10189999999999999\n",
      "Mean Smoothness 75% percentile = 0.110975\n",
      "Mean Smoothness Maximum = 0.1447\n",
      "\n",
      "\n",
      "MEAN COMPACTNESS\n",
      "Mean Compactness Count = 198\n",
      "Mean Compactness Mean = 0.14264777777777776\n",
      "Mean Compactness Standard Deviation = 0.049897601888512416\n",
      "Mean Compactness Minimum = 0.04605\n",
      "Mean Compactness 25% percentile = 0.11019999999999999\n",
      "Mean Compactness 50% percentile = 0.13175\n",
      "Mean Compactness 75% percentile = 0.17220000000000002\n",
      "Mean Compactness Maximum = 0.3114\n",
      "\n",
      "\n",
      "MEAN CONCAVITY\n",
      "Mean Concavity Count = 198\n",
      "Mean Concavity Mean = 0.15624277777777776\n",
      "Mean Concavity Standard Deviation = 0.07057226120534643\n",
      "Mean Concavity Minimum = 0.02398\n",
      "Mean Concavity 25% percentile = 0.10685\n",
      "Mean Concavity 50% percentile = 0.15134999999999998\n",
      "Mean Concavity 75% percentile = 0.2005\n",
      "Mean Concavity Maximum = 0.4268\n",
      "\n",
      "\n",
      "MEAN CONCAVE POINTS\n",
      "Mean Concave Points Count = 198\n",
      "Mean Concave Points Mean = 0.08677560606060604\n",
      "Mean Concave Points Standard Deviation = 0.03387663129061639\n",
      "Mean Concave Points Minimum = 0.02031\n",
      "Mean Concave Points 25% percentile = 0.06367\n",
      "Mean Concave Points 50% percentile = 0.086075\n",
      "Mean Concave Points 75% percentile = 0.103925\n",
      "Mean Concave Points Maximum = 0.2012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1A)\n",
    "\n",
    "#Summary statistics for mean_radius\n",
    "print(\"MEAN RADIUS\")\n",
    "print(f\"Mean Radius Count = {df['mean_radius'].count()}\")\n",
    "print(f\"Mean Radius Mean = {df['mean_radius'].mean()}\")\n",
    "print(f\"Mean Radius Standard Deviation = {df['mean_radius'].std()}\")\n",
    "print(f\"Mean Radius Minimum = {df['mean_radius'].min()}\")\n",
    "print(f\"Mean Radius 25% percentile = {df['mean_radius'].quantile(0.25)}\")\n",
    "print(f\"Mean Radius 50% percentile = {df['mean_radius'].quantile(0.50)}\")\n",
    "print(f\"Mean Radius 75% percentile = {df['mean_radius'].quantile(0.75)}\")\n",
    "print(f\"Mean Radius Maximum = {df['mean_radius'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN TEXTURE\")\n",
    "print(f\"Mean Texture Count = {df['mean_texture'].count()}\")\n",
    "print(f\"Mean Texture Mean = {df['mean_texture'].mean()}\")\n",
    "print(f\"Mean Texture Standard Deviation = {df['mean_texture'].std()}\")\n",
    "print(f\"Mean Texture Minimum = {df['mean_texture'].min()}\")\n",
    "print(f\"Mean Texture 25% percentile = {df['mean_texture'].quantile(0.25)}\")\n",
    "print(f\"Mean Texture 50% percentile = {df['mean_texture'].quantile(0.50)}\")\n",
    "print(f\"Mean Texture 75% percentile = {df['mean_texture'].quantile(0.75)}\")\n",
    "print(f\"Mean Texture Maximum = {df['mean_texture'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN PERIMETER\")\n",
    "print(f\"Mean Perimeter Count = {df['mean_perimeter'].count()}\")\n",
    "print(f\"Mean Perimeter Mean = {df['mean_perimeter'].mean()}\")\n",
    "print(f\"Mean Perimeter Standard Deviation = {df['mean_perimeter'].std()}\")\n",
    "print(f\"Mean Perimeter Minimum = {df['mean_perimeter'].min()}\")\n",
    "print(f\"Mean Perimeter 25% percentile = {df['mean_perimeter'].quantile(0.25)}\")\n",
    "print(f\"Mean Perimeter 50% percentile = {df['mean_perimeter'].quantile(0.50)}\")\n",
    "print(f\"Mean Perimeter 75% percentile = {df['mean_perimeter'].quantile(0.75)}\")\n",
    "print(f\"Mean Perimeter Maximum = {df['mean_perimeter'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN AREA\")\n",
    "print(f\"Mean Area Count = {df['mean_area'].count()}\")\n",
    "print(f\"Mean Area Mean = {df['mean_area'].mean()}\")\n",
    "print(f\"Mean Area Standard Deviation = {df['mean_area'].std()}\")\n",
    "print(f\"Mean Area Minimum = {df['mean_area'].min()}\")\n",
    "print(f\"Mean Area 25% percentile = {df['mean_area'].quantile(0.25)}\")\n",
    "print(f\"Mean Area 50% percentile = {df['mean_area'].quantile(0.50)}\")\n",
    "print(f\"Mean Area 75% percentile = {df['mean_area'].quantile(0.75)}\")\n",
    "print(f\"Mean Area Maximum = {df['mean_area'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN SMOOTHNESS\")\n",
    "print(f\"Mean Smoothness Count = {df['mean_smoothness'].count()}\")\n",
    "print(f\"Mean Smoothness Mean = {df['mean_smoothness'].mean()}\")\n",
    "print(f\"Mean Smoothness Standard Deviation = {df['mean_smoothness'].std()}\")\n",
    "print(f\"Mean Smoothness Minimum = {df['mean_smoothness'].min()}\")\n",
    "print(f\"Mean Smoothness 25% percentile = {df['mean_smoothness'].quantile(0.25)}\")\n",
    "print(f\"Mean Smoothness 50% percentile = {df['mean_smoothness'].quantile(0.50)}\")\n",
    "print(f\"Mean Smoothness 75% percentile = {df['mean_smoothness'].quantile(0.75)}\")\n",
    "print(f\"Mean Smoothness Maximum = {df['mean_smoothness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN COMPACTNESS\")\n",
    "print(f\"Mean Compactness Count = {df['mean_compactness'].count()}\")\n",
    "print(f\"Mean Compactness Mean = {df['mean_compactness'].mean()}\")\n",
    "print(f\"Mean Compactness Standard Deviation = {df['mean_compactness'].std()}\")\n",
    "print(f\"Mean Compactness Minimum = {df['mean_compactness'].min()}\")\n",
    "print(f\"Mean Compactness 25% percentile = {df['mean_compactness'].quantile(0.25)}\")\n",
    "print(f\"Mean Compactness 50% percentile = {df['mean_compactness'].quantile(0.50)}\")\n",
    "print(f\"Mean Compactness 75% percentile = {df['mean_compactness'].quantile(0.75)}\")\n",
    "print(f\"Mean Compactness Maximum = {df['mean_compactness'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVITY\")\n",
    "print(f\"Mean Concavity Count = {df['mean_concavity'].count()}\")\n",
    "print(f\"Mean Concavity Mean = {df['mean_concavity'].mean()}\")\n",
    "print(f\"Mean Concavity Standard Deviation = {df['mean_concavity'].std()}\")\n",
    "print(f\"Mean Concavity Minimum = {df['mean_concavity'].min()}\")\n",
    "print(f\"Mean Concavity 25% percentile = {df['mean_concavity'].quantile(0.25)}\")\n",
    "print(f\"Mean Concavity 50% percentile = {df['mean_concavity'].quantile(0.50)}\")\n",
    "print(f\"Mean Concavity 75% percentile = {df['mean_concavity'].quantile(0.75)}\")\n",
    "print(f\"Mean Concavity Maximum = {df['mean_concavity'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"MEAN CONCAVE POINTS\")\n",
    "print(f\"Mean Concave Points Count = {df['mean_concave_points'].count()}\")\n",
    "print(f\"Mean Concave Points Mean = {df['mean_concave_points'].mean()}\")\n",
    "print(f\"Mean Concave Points Standard Deviation = {df['mean_concave_points'].std()}\")\n",
    "print(f\"Mean Concave Points Minimum = {df['mean_concave_points'].min()}\")\n",
    "print(f\"Mean Concave Points 25% percentile = {df['mean_concave_points'].quantile(0.25)}\")\n",
    "print(f\"Mean Concave Points 50% percentile = {df['mean_concave_points'].quantile(0.50)}\")\n",
    "print(f\"Mean Concave Points 75% percentile = {df['mean_concave_points'].quantile(0.75)}\")\n",
    "print(f\"Mean Concave Points Maximum = {df['mean_concave_points'].max()}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "3879b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTCOME\n",
      "Outcome Count = 198\n",
      "Outcome unique values are = ['N' 'R']\n",
      "Count of each unique values are = N    151\n",
      "R     47\n",
      "Name: outcome, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 1B)\n",
    "\n",
    "print(\"OUTCOME\")\n",
    "print(f\"Outcome Count = {df['outcome'].count()}\")\n",
    "print(f\"Outcome unique values are = {df['outcome'].unique()}\")\n",
    "print(f\"Count of each unique values are = {df['outcome'].value_counts()}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "9dfb77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1C)\n",
    "df['outcome'].replace('N', 0, inplace=True) \n",
    "df['outcome'].replace('R', 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "2e1e8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean_perimeter  se_perimeter\n",
      "mean_perimeter        1.000000      0.609964\n",
      "se_perimeter          0.609964      1.000000\n"
     ]
    }
   ],
   "source": [
    "# Question 1E)\n",
    "print(df[['mean_perimeter','se_perimeter']].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "3df45305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Class for cleaning up data and data manipulation in general\n",
    "class DataManipulation:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def cleanUpData(self):\n",
    "        self.df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    def divideData(self):\n",
    "        msk = np.random.rand(len(self.df)) < 0.8\n",
    "        train = df[msk]\n",
    "        test = df[~msk]\n",
    "\n",
    "        return train, test\n",
    "    \n",
    "    def reqColsFromData(self, cols, data : pd.DataFrame):\n",
    "        finalData = []\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            predictorsArr = []\n",
    "\n",
    "            for col in cols:\n",
    "                predictorsArr.append(row[col])\n",
    "        \n",
    "            finalData.append((predictorsArr, row['outcome']))\n",
    "            \n",
    "        \n",
    "        return finalData\n",
    "\n",
    "\n",
    "\n",
    "# Logistic regression model Class with all the components required for Logistic regression\n",
    "class LogisticRegression:\n",
    "    \n",
    "    trainingData = None\n",
    "    testData = None\n",
    "    maxNoOfIterations = 50\n",
    "\n",
    "    def __init__(self, trainingData, testData, thetas, lr, isRegularization):\n",
    "        self.trainingData = trainingData\n",
    "        self.testData = testData\n",
    "        self.thetas = thetas\n",
    "        self.lr = lr\n",
    "        self.isRegularization = isRegularization\n",
    "        \n",
    "        \n",
    "    def getFeatures2D(self, data):\n",
    "        if data != None:\n",
    "            features = [x[0] for x in data]\n",
    "            return features\n",
    "\n",
    "    def getOutputs(self, data):\n",
    "        if data != None:\n",
    "            output = [Decimal(x[1]) for x in data]\n",
    "            return output\n",
    "\n",
    "    def performLinearRegression(self):\n",
    "        self.iterate()\n",
    "\n",
    "    def computePredictedOutput(self, thetas, data):\n",
    "        predictedOutputs = []\n",
    "\n",
    "        for x in self.getFeatures2D(data):\n",
    "            y = Decimal(thetas[0])\n",
    "\n",
    "            for idx, i in enumerate(x):\n",
    "                y += (Decimal(thetas[idx + 1]) * Decimal(i))\n",
    "\n",
    "            Y = Decimal(1/(1+(Decimal('%.5f'%(math.exp(-y))))))\n",
    "            \n",
    "            predictedOutputs.append(Y)\n",
    "\n",
    "        return predictedOutputs\n",
    "    \n",
    "    def calculateCost(self, predictedOutputs, data):\n",
    "        outputs = self.getOutputs(data)\n",
    "        dataLen = len(self.getFeatures2D(data))\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            result = (x - outputs[idx]) ** 2\n",
    "            total += result\n",
    "\n",
    "        cost = total / Decimal((2 * dataLen))\n",
    "        return cost\n",
    "    \n",
    "\n",
    "    def calculateGradientDescent(self, B, index,  predictedOutputs, isIntercept):\n",
    "        features = self.getFeatures2D(self.trainingData)\n",
    "        outputs = self.getOutputs(self.trainingData)\n",
    "\n",
    "        dataLen = Decimal(len(features))\n",
    "        \n",
    "        total = 0\n",
    "\n",
    "        for idx, x in enumerate(features):\n",
    "\n",
    "            if isIntercept:\n",
    "                result = (predictedOutputs[idx] - outputs[idx])\n",
    "            else:\n",
    "                result = (predictedOutputs[idx] - outputs[idx]) * Decimal(x[index]) \n",
    "\n",
    "\n",
    "            total += result\n",
    "\n",
    "        if self.isRegularization and (not isIntercept):\n",
    "            total += (100 * B) / dataLen # regularization coefficent = 100\n",
    "        \n",
    "        change = (Decimal(self.lr) * total) / dataLen\n",
    "\n",
    "        newB = B - change\n",
    "\n",
    "        \n",
    "        return newB\n",
    "    \n",
    "    def iterate(self):\n",
    "\n",
    "        for i in range(self.maxNoOfIterations):\n",
    "\n",
    "            predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "\n",
    "            for idx, b in enumerate(self.thetas):\n",
    "                if idx == 0:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, True)\n",
    "                else:\n",
    "                    newB = self.calculateGradientDescent(b, (idx - 1), predictedOutputs, False)\n",
    "\n",
    "                self.thetas[idx] = newB\n",
    "        \n",
    "        self.printResults()\n",
    "\n",
    "    \n",
    "    def calculateModelPerformance(self, predictedOutputs, data):\n",
    "        outputs = self.getOutputs(data)\n",
    "       \n",
    "        accuratePredictionCount = 0\n",
    "        count = 0\n",
    "\n",
    "        for idx, x in enumerate(predictedOutputs):\n",
    "            print(x)\n",
    "            roundedOpt = None\n",
    "            count += 1\n",
    "            if x > 0.7:   #Setting the threshold value at 0.5\n",
    "                roundedOpt = 1\n",
    "            else:\n",
    "                roundedOpt = 0\n",
    "\n",
    "            if roundedOpt == outputs[idx]:\n",
    "                accuratePredictionCount += 1\n",
    "            \n",
    "\n",
    "        return (accuratePredictionCount / count)\n",
    "\n",
    "    def printResults(self):\n",
    "        print(\"The values of the Thetas/ Weights are\")\n",
    "        print(self.thetas)\n",
    "\n",
    "        print(\"Model performance of the Training data set is\")\n",
    "        predictedOutputs = self.computePredictedOutput(self.thetas, self.trainingData)\n",
    "        performancePercent = self.calculateModelPerformance(predictedOutputs, self.trainingData)\n",
    "\n",
    "        print(performancePercent)\n",
    "\n",
    "        print(\"Model performance of the Test data is\")\n",
    "        predictedOutputs1 = self.computePredictedOutput(self.thetas, self.testData)\n",
    "        performancePercent1 = self.calculateModelPerformance(predictedOutputs1, self.testData)\n",
    "        print(performancePercent1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "5ccbd89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready for logistic regression\n",
    "\n",
    "dm = DataManipulation(df)\n",
    "dm.cleanUpData()\n",
    "train, test = dm.divideData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "ff0d2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the Thetas/ Weights are\n",
      "[Decimal('-0.0001718076446254189412739667829'), Decimal('0.01262092408169723918060540714')]\n",
      "Model performance of the Training data set is\n",
      "1\n",
      "1\n",
      "0.9924080782017565622984171091\n",
      "1\n",
      "0.9993204620857816684654434984\n",
      "0.9975460367495959938551164136\n",
      "0.9999600015999360025598976041\n",
      "0.9999500024998750062496875156\n",
      "0.9999500024998750062496875156\n",
      "0.9997600575861793169639286571\n",
      "0.9999600015999360025598976041\n",
      "0.9998600195972563841062251285\n",
      "0.9999900000999990000099999000\n",
      "0.9999900000999990000099999000\n",
      "0.9997100840756180707594797509\n",
      "1\n",
      "0.9999000099990000999900009999\n",
      "0.9999900000999990000099999000\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "0.9999600015999360025598976041\n",
      "0.9996601155607093588180018794\n",
      "0.9998500224966255061740738889\n",
      "0.9908347783007183552142680208\n",
      "1\n",
      "0.9987814865863646351451229500\n",
      "0.9988313673002586973241307670\n",
      "0.9998800143982722073351197856\n",
      "0.9997500624843789052736815796\n",
      "0.9997100840756180707594797509\n",
      "0.9981633793819372354867044638\n",
      "0.9997800483893543420447501550\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "0.9997000899730080975707287814\n",
      "0.9987615356957372857656505933\n",
      "0.9998200323941690495710772061\n",
      "0.9999500024998750062496875156\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999600015999360025598976041\n",
      "1\n",
      "0.9983228176663205814232090089\n",
      "0.9998100360931423029624371369\n",
      "0.9999700008999730008099757007\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999900000999990000099999000\n",
      "0.9992006394884092725819344524\n",
      "0.9999100080992710656040956314\n",
      "1\n",
      "1\n",
      "0.9999400035997840129592224467\n",
      "0.9998700168978032855728755262\n",
      "0.9995502024089159878054875306\n",
      "0.9994103478947421021597257618\n",
      "1\n",
      "1\n",
      "0.9999900000999990000099999000\n",
      "0.9995502024089159878054875306\n",
      "1\n",
      "1\n",
      "0.9982530571499875218367856252\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "0.9995002498750624687656171914\n",
      "1\n",
      "0.9998800143982722073351197856\n",
      "0.9999400035997840129592224467\n",
      "0.9999200063994880409567234621\n",
      "1\n",
      "0.9999900000999990000099999000\n",
      "0.9999300048996570240083194176\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999600015999360025598976041\n",
      "0.9956787542067427365234880618\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "0.9999300048996570240083194176\n",
      "1\n",
      "0.9998800143982722073351197856\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9997700528878357977665137018\n",
      "1\n",
      "0.9998900120986691463938966714\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "1\n",
      "0.9994802702594650781593571343\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999700008999730008099757007\n",
      "1\n",
      "0.9999800003999920001599968001\n",
      "1\n",
      "1\n",
      "0.9994602914426209846682791293\n",
      "1\n",
      "0.9999000099990000999900009999\n",
      "0.9998600195972563841062251285\n",
      "1\n",
      "1\n",
      "0.9998800143982722073351197856\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999800003999920001599968001\n",
      "0.9994602914426209846682791293\n",
      "0.9999900000999990000099999000\n",
      "1\n",
      "0.9999400035997840129592224467\n",
      "0.9999400035997840129592224467\n",
      "1\n",
      "1\n",
      "0.9992405771613573684000159878\n",
      "1\n",
      "1\n",
      "0.9979641531276196559019600016\n",
      "1\n",
      "1\n",
      "0.9997500624843789052736815796\n",
      "1\n",
      "0.9999900000999990000099999000\n",
      "0.22602739726027396\n",
      "Model performance of the Test data is\n",
      "1\n",
      "0.9985820135407721036128697250\n",
      "1\n",
      "0.9961647656522388803108034069\n",
      "0.9991407389644905381372020063\n",
      "0.9991806718490837513239143902\n",
      "0.9989710598083973507287493881\n",
      "1\n",
      "1\n",
      "0.9993703966501104304288298372\n",
      "1\n",
      "1\n",
      "0.9998600195972563841062251285\n",
      "0.9996601155607093588180018794\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9997900440907409444016756481\n",
      "1\n",
      "0.9998800143982722073351197856\n",
      "0.9999700008999730008099757007\n",
      "0.9999900000999990000099999000\n",
      "0.9999700008999730008099757007\n",
      "1\n",
      "0.9896874567011737693236475921\n",
      "1\n",
      "1\n",
      "0.9999600015999360025598976041\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9999300048996570240083194176\n",
      "1\n",
      "0.9999100080992710656040956314\n",
      "0.9999900000999990000099999000\n",
      "0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "finalTrain = dm.reqColsFromData(['mean_area'], train)\n",
    "finalTest = dm.reqColsFromData(['mean_area'], test)\n",
    "\n",
    "lr1 = LogisticRegression(finalTrain, finalTest, [0, 0], 0.0001, False) # passing in Training data, Test data, max no of iteration, starting theta values,\n",
    "                                                                  # the learning date and regularization\n",
    "lr1.performLinearRegression()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
